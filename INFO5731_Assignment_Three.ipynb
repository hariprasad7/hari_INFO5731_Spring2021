{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hariprasad7/hari_INFO5731_Spring2021/blob/main/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on \n",
        "\n",
        "1.   List item\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "2.   List item\n",
        "\n",
        "the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "478ca101-c66c-4149-e7ef-a15308609d2a"
      },
      "source": [
        "from textblob  import Word\r\n",
        "from textblob  import TextBlob\r\n",
        "import nltk\r\n",
        "import pandas as pd\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "f = pd.read_csv('Abstract.csv')\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "word_vectorizer = CountVectorizer(ngram_range = (3,3), analyzer = 'word')\r\n",
        "sparse_matrix = word_vectorizer.fit_transform(f['Abstract'].values.astype('U'))\r\n",
        "frequencies = sum(sparse_matrix).toarray()[0]\r\n",
        "df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['Frequency'])\r\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12364 lex sign</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13 patterns comprise</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16 introduction this</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18 introduction since</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958 yet in</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>years one of</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yet at the</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yet in the</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yield significant improvements</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>your words language</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3331 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Frequency\n",
              "12364 lex sign                          1\n",
              "13 patterns comprise                    1\n",
              "16 introduction this                    1\n",
              "18 introduction since                   1\n",
              "1958 yet in                             1\n",
              "...                                   ...\n",
              "years one of                            1\n",
              "yet at the                              1\n",
              "yet in the                              1\n",
              "yield significant improvements          1\n",
              "your words language                     1\n",
              "\n",
              "[3331 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-u0uGEUOEPf",
        "outputId": "4882a7f8-d3fc-46d6-80f7-6b72bb045144"
      },
      "source": [
        "from collections import Counter\r\n",
        "import itertools\r\n",
        "import collections\r\n",
        "from nltk import ngrams\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "l=[]\r\n",
        "for i in f['Abstract']:\r\n",
        "  l.append(word_tokenize(i))\r\n",
        "cleanedsent=[x for x in  l if x != []]\r\n",
        "iterations=list(itertools.chain.from_iterable(cleanedsent))\r\n",
        "bi_grams=nltk.bigrams(iterations)\r\n",
        "freq_dist=nltk.FreqDist(bi_grams)\r\n",
        "dict1=dict(freq_dist)\r\n",
        "for word in dict1:\r\n",
        "  print(str(word)+ ':' + str(dict1[word]/iterations.count(word[0])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Abstract', 'not'):0.6153846153846154\n",
            "('not', 'found'):0.5714285714285714\n",
            "('found', 'describe'):0.125\n",
            "('describe', 'a'):0.5555555555555556\n",
            "('a', 'method'):0.0196078431372549\n",
            "('method', 'for'):0.4\n",
            "('for', 'statistical'):0.017857142857142856\n",
            "('statistical', 'modeling'):0.14285714285714285\n",
            "('modeling', 'based'):0.3333333333333333\n",
            "('based', 'on'):0.625\n",
            "('on', 'maximum'):0.043478260869565216\n",
            "('maximum', 'entropy'):1.0\n",
            "('entropy', '.'):0.5\n",
            "('.', 'We'):0.0958904109589041\n",
            "('We', 'present'):0.08333333333333333\n",
            "('present', 'a'):0.75\n",
            "('a', 'maximum-likelihood'):0.00980392156862745\n",
            "('maximum-likelihood', 'approach'):1.0\n",
            "('approach', 'for'):0.36363636363636365\n",
            "('for', 'automatically'):0.017857142857142856\n",
            "('automatically', 'constructing'):0.3333333333333333\n",
            "('constructing', 'maximum'):1.0\n",
            "('entropy', 'models'):0.5\n",
            "('models', 'and'):0.25\n",
            "('and', 'describe'):0.00847457627118644\n",
            "('describe', 'how'):0.1111111111111111\n",
            "('how', 'to'):0.2\n",
            "('to', 'implement'):0.013513513513513514\n",
            "('implement', 'this'):1.0\n",
            "('this', 'approach'):0.045454545454545456\n",
            "('approach', 'efficiently'):0.09090909090909091\n",
            "('efficiently', ','):1.0\n",
            "(',', 'using'):0.006578947368421052\n",
            "('using', 'as'):0.09090909090909091\n",
            "('as', 'examples'):0.06666666666666667\n",
            "('examples', 'several'):1.0\n",
            "('several', 'problems'):0.25\n",
            "('problems', 'in'):0.3333333333333333\n",
            "('in', 'natural'):0.18666666666666668\n",
            "('natural', 'language'):0.953125\n",
            "('language', 'processing'):0.6705882352941176\n",
            "('processing', '.'):0.171875\n",
            "('.', 'Scaling'):0.00684931506849315\n",
            "('Scaling', 'conditional'):1.0\n",
            "('conditional', 'random'):1.0\n",
            "('random', 'fields'):1.0\n",
            "('fields', 'for'):0.3333333333333333\n",
            "('for', 'natural'):0.07142857142857142\n",
            "('processing', 'Terms'):0.015625\n",
            "('Terms', 'and'):1.0\n",
            "('and', 'Conditions'):0.01694915254237288\n",
            "('Conditions', ':'):1.0\n",
            "(':', 'Terms'):0.05263157894736842\n",
            "(':', 'Copyright'):0.05263157894736842\n",
            "('Copyright', 'in'):1.0\n",
            "('in', 'works'):0.013333333333333334\n",
            "('works', 'deposited'):0.5\n",
            "('deposited', 'in'):1.0\n",
            "('in', 'Minerva'):0.013333333333333334\n",
            "('Minerva', 'Access'):1.0\n",
            "('Access', 'is'):1.0\n",
            "('is', 'retained'):0.018518518518518517\n",
            "('retained', 'by'):1.0\n",
            "('by', 'the'):0.16666666666666666\n",
            "('the', 'The'):0.005434782608695652\n",
            "('The', 'paper'):0.07692307692307693\n",
            "('paper', 'addresses'):0.047619047619047616\n",
            "('addresses', 'the'):1.0\n",
            "('the', 'issue'):0.005434782608695652\n",
            "('issue', 'of'):0.6666666666666666\n",
            "('of', 'cooperation'):0.005681818181818182\n",
            "('cooperation', 'between'):0.5\n",
            "('between', 'linguistics'):0.25\n",
            "('linguistics', 'and'):0.4\n",
            "('and', 'natural'):0.00847457627118644\n",
            "('processing', '('):0.1875\n",
            "('(', 'NLP'):0.43137254901960786\n",
            "('NLP', ')'):0.4772727272727273\n",
            "(')', ','):0.19148936170212766\n",
            "(',', 'in'):0.02631578947368421\n",
            "('in', 'general'):0.02666666666666667\n",
            "('general', ','):0.3333333333333333\n",
            "(',', 'and'):0.125\n",
            "('and', 'between'):0.00847457627118644\n",
            "('and', 'machine'):0.03389830508474576\n",
            "('machine', 'translation'):0.21428571428571427\n",
            "('translation', '('):0.25\n",
            "('(', 'MT'):0.0196078431372549\n",
            "('MT', ')'):1.0\n",
            "('in', 'particular'):0.02666666666666667\n",
            "('particular', '.'):0.2\n",
            "('.', 'It'):0.03424657534246575\n",
            "('It', 'focuses'):0.2\n",
            "('focuses', 'on'):1.0\n",
            "('on', 'just'):0.043478260869565216\n",
            "('just', 'one'):1.0\n",
            "('one', 'direction'):0.2\n",
            "('direction', 'of'):1.0\n",
            "('of', 'such'):0.005681818181818182\n",
            "('such', 'cooperation'):0.25\n",
            "('cooperation', ','):0.5\n",
            "(',', 'namely'):0.006578947368421052\n",
            "('namely', 'applications'):1.0\n",
            "('applications', 'of'):0.18181818181818182\n",
            "('of', 'linguistics'):0.005681818181818182\n",
            "('linguistics', 'to'):0.2\n",
            "('to', 'NLP'):0.013513513513513514\n",
            "('NLP', ','):0.022727272727272728\n",
            "(',', 'virtually'):0.006578947368421052\n",
            "('virtually', 'In'):1.0\n",
            "('In', 'most'):0.058823529411764705\n",
            "('most', 'natural'):0.5\n",
            "('processing', 'applications'):0.015625\n",
            "('applications', ','):0.09090909090909091\n",
            "(',', 'Description'):0.013157894736842105\n",
            "('Description', 'Logics'):1.0\n",
            "('Logics', 'have'):0.5\n",
            "('have', 'been'):0.5\n",
            "('been', 'used'):0.23076923076923078\n",
            "('used', 'to'):0.36363636363636365\n",
            "('to', 'encode'):0.013513513513513514\n",
            "('encode', 'in'):0.5\n",
            "('in', 'a'):0.08\n",
            "('a', 'knowledge'):0.0196078431372549\n",
            "('knowledge', 'base'):0.16666666666666666\n",
            "('base', 'some'):0.5\n",
            "('some', 'syntactic'):0.2\n",
            "('syntactic', ','):0.16666666666666666\n",
            "(',', 'semantic'):0.013157894736842105\n",
            "('semantic', ','):0.125\n",
            "('and', 'pragmatic'):0.00847457627118644\n",
            "('pragmatic', 'elements'):1.0\n",
            "('elements', 'needed'):0.3333333333333333\n",
            "('needed', 'to'):1.0\n",
            "('to', 'drive'):0.02702702702702703\n",
            "('drive', 'the'):1.0\n",
            "('the', 'semantic'):0.010869565217391304\n",
            "('semantic', 'interpretation'):0.25\n",
            "('interpretation', 'and'):0.3333333333333333\n",
            "('and', 'the'):0.06779661016949153\n",
            "('the', 'natural'):0.010869565217391304\n",
            "('language', 'generation'):0.011764705882352941\n",
            "('generation', 'processes'):0.5\n",
            "('processes', '.'):0.25\n",
            "('.', 'More'):0.00684931506849315\n",
            "('More', 'recently'):1.0\n",
            "('recently', ','):0.5\n",
            "('been', 'We'):0.07692307692307693\n",
            "('We', 'propose'):0.08333333333333333\n",
            "('propose', 'a'):1.0\n",
            "('a', 'unified'):0.00980392156862745\n",
            "('unified', 'neural'):1.0\n",
            "('neural', 'network'):1.0\n",
            "('network', 'architecture'):0.4\n",
            "('architecture', 'and'):0.25\n",
            "('and', 'learning'):0.01694915254237288\n",
            "('learning', 'algorithm'):0.05\n",
            "('algorithm', 'that'):1.0\n",
            "('that', 'can'):0.02631578947368421\n",
            "('can', 'be'):0.625\n",
            "('be', 'applied'):0.038461538461538464\n",
            "('applied', 'to'):0.5\n",
            "('to', 'various'):0.013513513513513514\n",
            "('various', 'natural'):0.125\n",
            "('processing', 'tasks'):0.03125\n",
            "('tasks', 'including'):0.0625\n",
            "('including', 'part-of-speech'):0.125\n",
            "('part-of-speech', 'tagging'):0.5\n",
            "('tagging', ','):0.5\n",
            "(',', 'chunking'):0.006578947368421052\n",
            "('chunking', ','):1.0\n",
            "(',', 'named'):0.013157894736842105\n",
            "('named', 'entity'):1.0\n",
            "('entity', 'recognition'):0.5\n",
            "('recognition', ','):0.3333333333333333\n",
            "('and', 'semantic'):0.01694915254237288\n",
            "('semantic', 'role'):0.125\n",
            "('role', 'labeling'):0.3333333333333333\n",
            "('labeling', '.'):1.0\n",
            "('.', 'This'):0.10273972602739725\n",
            "('This', 'versatility'):0.034482758620689655\n",
            "('versatility', 'is'):1.0\n",
            "('is', 'achieved'):0.018518518518518517\n",
            "('achieved', 'by'):1.0\n",
            "('by', 'trying'):0.05555555555555555\n",
            "('trying', 'to'):1.0\n",
            "('to', 'avoid'):0.02702702702702703\n",
            "('avoid', 'task'):0.3333333333333333\n",
            "('task', 'Natural'):0.25\n",
            "('Natural', 'Language'):0.6551724137931034\n",
            "('Language', 'Processing'):0.8695652173913043\n",
            "('Processing', 'The'):0.05\n",
            "('The', 'subject'):0.038461538461538464\n",
            "('subject', 'of'):0.5\n",
            "('of', 'Natural'):0.017045454545454544\n",
            "('Processing', 'can'):0.05\n",
            "('be', 'considered'):0.038461538461538464\n",
            "('considered', 'in'):1.0\n",
            "('in', 'both'):0.02666666666666667\n",
            "('both', 'broad'):0.2\n",
            "('broad', 'and'):0.3333333333333333\n",
            "('and', 'narrow'):0.00847457627118644\n",
            "('narrow', 'senses'):1.0\n",
            "('senses', '.'):0.5\n",
            "('.', 'In'):0.0547945205479452\n",
            "('In', 'the'):0.11764705882352941\n",
            "('the', 'broad'):0.005434782608695652\n",
            "('broad', 'sense'):0.3333333333333333\n",
            "('sense', ','):0.2\n",
            "(',', 'it'):0.019736842105263157\n",
            "('it', 'covers'):0.1\n",
            "('covers', 'processing'):1.0\n",
            "('processing', 'issues'):0.015625\n",
            "('issues', 'at'):0.5\n",
            "('at', 'all'):0.14285714285714285\n",
            "('all', 'levels'):0.14285714285714285\n",
            "('levels', 'of'):1.0\n",
            "('of', 'natural'):0.07386363636363637\n",
            "('language', 'understanding'):0.023529411764705882\n",
            "('understanding', ','):0.16666666666666666\n",
            "(',', 'including'):0.006578947368421052\n",
            "('including', 'speech'):0.125\n",
            "('speech', 'recognition'):0.375\n",
            "(',', 'syntactic'):0.013157894736842105\n",
            "('syntactic', 'and'):0.16666666666666666\n",
            "('semantic', 'analysis'):0.125\n",
            "('analysis', 'of'):0.2727272727272727\n",
            "('of', 'sentences'):0.005681818181818182\n",
            "('sentences', 'Robots'):1.0\n",
            "('Robots', 'that'):1.0\n",
            "('that', 'interact'):0.02631578947368421\n",
            "('interact', 'with'):1.0\n",
            "('with', 'humans'):0.047619047619047616\n",
            "('humans', 'face-to-face'):0.25\n",
            "('face-to-face', 'using'):0.5\n",
            "('using', 'natural'):0.18181818181818182\n",
            "('language', 'need'):0.011764705882352941\n",
            "('need', 'to'):0.3333333333333333\n",
            "('to', 'be'):0.0945945945945946\n",
            "('be', 'responsive'):0.038461538461538464\n",
            "('responsive', 'to'):1.0\n",
            "('to', 'the'):0.08108108108108109\n",
            "('the', 'way'):0.016304347826086956\n",
            "('way', 'humans'):0.4\n",
            "('humans', 'use'):0.25\n",
            "('use', 'language'):0.08333333333333333\n",
            "('language', 'in'):0.023529411764705882\n",
            "('in', 'those'):0.013333333333333334\n",
            "('those', 'situations'):0.5\n",
            "('situations', '.'):1.0\n",
            "('a', 'psychologicallyinspired'):0.00980392156862745\n",
            "('psychologicallyinspired', 'natural'):1.0\n",
            "('processing', 'system'):0.015625\n",
            "('system', 'for'):0.15384615384615385\n",
            "('for', 'robots'):0.017857142857142856\n",
            "('robots', 'which'):1.0\n",
            "('which', 'performs'):0.2222222222222222\n",
            "('performs', 'incremental'):0.5\n",
            "('incremental', 'semantic'):1.0\n",
            "('interpretation', 'of'):0.3333333333333333\n",
            "('of', 'spoken'):0.005681818181818182\n",
            "('spoken', 'utterances'):0.25\n",
            "('utterances', 'Natural'):1.0\n",
            "('Natural', 'languages'):0.10344827586206896\n",
            "('languages', 'are'):0.5\n",
            "('are', 'languages'):0.038461538461538464\n",
            "('languages', 'spoken'):0.16666666666666666\n",
            "('spoken', 'by'):0.25\n",
            "('by', 'humans'):0.05555555555555555\n",
            "('humans', '.'):0.25\n",
            "('.', 'Currently'):0.00684931506849315\n",
            "('Currently', 'we'):1.0\n",
            "('we', 'are'):0.058823529411764705\n",
            "('are', 'not'):0.15384615384615385\n",
            "('not', 'yet'):0.07142857142857142\n",
            "('yet', 'at'):0.5\n",
            "('at', 'the'):0.5714285714285714\n",
            "('the', 'point'):0.005434782608695652\n",
            "('point', 'where'):0.25\n",
            "('where', 'these'):0.5\n",
            "('these', 'languages'):0.2\n",
            "('languages', 'in'):0.16666666666666666\n",
            "('in', 'all'):0.013333333333333334\n",
            "('all', 'of'):0.14285714285714285\n",
            "('of', 'their'):0.005681818181818182\n",
            "('their', 'unprocessed'):0.25\n",
            "('unprocessed', 'forms'):1.0\n",
            "('forms', 'can'):0.3333333333333333\n",
            "('be', 'understood'):0.038461538461538464\n",
            "('understood', 'by'):0.5\n",
            "('by', 'computers'):0.05555555555555555\n",
            "('computers', '.'):0.3333333333333333\n",
            "('.', 'Natural'):0.04794520547945205\n",
            "('Natural', 'language'):0.20689655172413793\n",
            "('processing', 'is'):0.046875\n",
            "('is', 'the'):0.14814814814814814\n",
            "('the', 'collection'):0.005434782608695652\n",
            "('collection', 'of'):0.5\n",
            "('of', 'techniques'):0.005681818181818182\n",
            "('techniques', 'employed'):0.07142857142857142\n",
            "('employed', 'to'):0.5\n",
            "('to', 'try'):0.013513513513513514\n",
            "('try', 'and'):1.0\n",
            "('and', 'accomplish'):0.00847457627118644\n",
            "('accomplish', 'that'):1.0\n",
            "('that', 'goal'):0.02631578947368421\n",
            "('goal', '.'):0.3333333333333333\n",
            "('.', 'The'):0.1506849315068493\n",
            "('The', 'field'):0.038461538461538464\n",
            "('field', 'of'):0.2\n",
            "('natural', 'ABSTRACT'):0.015625\n",
            "('ABSTRACT', ':'):0.75\n",
            "(':', 'Ambiguity'):0.05263157894736842\n",
            "('Ambiguity', 'can'):1.0\n",
            "('be', 'referred'):0.038461538461538464\n",
            "('referred', 'as'):1.0\n",
            "('as', 'the'):0.06666666666666667\n",
            "('the', 'ability'):0.005434782608695652\n",
            "('ability', 'of'):1.0\n",
            "('of', 'having'):0.011363636363636364\n",
            "('having', 'more'):0.5\n",
            "('more', 'than'):0.2222222222222222\n",
            "('than', 'one'):0.5\n",
            "('one', 'meaning'):0.2\n",
            "('meaning', 'or'):0.5\n",
            "('or', 'being'):0.058823529411764705\n",
            "('being', 'understood'):0.5\n",
            "('understood', 'in'):0.5\n",
            "('in', 'more'):0.013333333333333334\n",
            "('one', 'way'):0.2\n",
            "('way', '.'):0.2\n",
            "('are', 'ambiguous'):0.038461538461538464\n",
            "('ambiguous', ','):1.0\n",
            "(',', 'so'):0.006578947368421052\n",
            "('so', 'computers'):0.3333333333333333\n",
            "('computers', 'are'):0.3333333333333333\n",
            "('not', 'able'):0.07142857142857142\n",
            "('able', 'to'):1.0\n",
            "('to', 'understand'):0.013513513513513514\n",
            "('understand', 'language'):1.0\n",
            "('language', 'the'):0.011764705882352941\n",
            "('way', 'people'):0.2\n",
            "('people', 'do'):1.0\n",
            "('do', '.'):0.3333333333333333\n",
            "('Processing', '('):0.55\n",
            "(')', 'is'):0.1276595744680851\n",
            "('is', 'concerned'):0.018518518518518517\n",
            "('concerned', 'with'):1.0\n",
            "('with', 'the'):0.2857142857142857\n",
            "('the', 'development'):0.021739130434782608\n",
            "('development', 'Introduction'):0.1111111111111111\n",
            "('Introduction', 'Statistical'):0.2\n",
            "('Statistical', 'natural'):1.0\n",
            "('(', 'SNLP'):0.0196078431372549\n",
            "('SNLP', ')'):0.5\n",
            "('is', 'a'):0.16666666666666666\n",
            "('a', 'field'):0.00980392156862745\n",
            "('field', 'lying'):0.2\n",
            "('lying', 'in'):1.0\n",
            "('in', 'the'):0.13333333333333333\n",
            "('the', 'intersection'):0.005434782608695652\n",
            "('intersection', 'of'):1.0\n",
            "('processing', 'and'):0.015625\n",
            "('machine', 'learning'):0.6428571428571429\n",
            "('learning', '.'):0.15\n",
            "('.', 'SNLP'):0.00684931506849315\n",
            "('SNLP', 'di'):0.5\n",
            "('di', '#'):1.0\n",
            "('#', 'ers'):1.0\n",
            "('ers', 'from'):1.0\n",
            "('from', 'traditional'):0.05555555555555555\n",
            "('traditional', 'natural'):0.5\n",
            "('processing', 'in'):0.015625\n",
            "('in', 'that'):0.013333333333333334\n",
            "('that', 'instead'):0.02631578947368421\n",
            "('instead', 'of'):1.0\n",
            "('having', 'a'):0.5\n",
            "('a', 'linguist'):0.00980392156862745\n",
            "('linguist', 'manually'):1.0\n",
            "('manually', 'construct'):0.5\n",
            "('construct', 'some'):1.0\n",
            "('some', 'model'):0.2\n",
            "('model', 'of'):0.42857142857142855\n",
            "('of', 'a'):0.05113636363636364\n",
            "('a', 'given'):0.00980392156862745\n",
            "('given', 'linguistic'):0.25\n",
            "('linguistic', 'text'):0.14285714285714285\n",
            "('text', 'directly'):0.1\n",
            "('directly', '('):1.0\n",
            "('(', 'rather'):0.0196078431372549\n",
            "('rather', 'than'):0.6666666666666666\n",
            "('than', 'e.g'):0.25\n",
            "('e.g', '.'):1.0\n",
            "('.', 'titles'):0.00684931506849315\n",
            "('titles', 'and'):1.0\n",
            "('and', 'abstracts'):0.00847457627118644\n",
            "('abstracts', ')'):1.0\n",
            "('and', 'suggests'):0.00847457627118644\n",
            "('suggests', 'appropriate'):1.0\n",
            "('appropriate', 'approaches'):1.0\n",
            "('approaches', 'to'):0.3333333333333333\n",
            "('to', 'doing'):0.013513513513513514\n",
            "('doing', 'this'):1.0\n",
            "('this', ','):0.045454545454545456\n",
            "(',', 'with'):0.006578947368421052\n",
            "('with', 'a'):0.23809523809523808\n",
            "('a', 'focus'):0.029411764705882353\n",
            "('focus', 'on'):0.8333333333333334\n",
            "('on', 'the'):0.2608695652173913\n",
            "('the', 'role'):0.010869565217391304\n",
            "('role', 'of'):0.6666666666666666\n",
            "('paper', 'also'):0.047619047619047616\n",
            "('also', 'comments'):0.2\n",
            "('comments', 'on'):1.0\n",
            "('on', 'possible'):0.043478260869565216\n",
            "('possible', 'connections'):0.5\n",
            "('connections', 'with'):1.0\n",
            "('with', 'data'):0.047619047619047616\n",
            "('data', 'and'):0.16666666666666666\n",
            "('and', 'knowledge'):0.00847457627118644\n",
            "('knowledge', 'retrieval'):0.08333333333333333\n",
            "('retrieval', ','):0.1111111111111111\n",
            "('and', 'concludes'):0.00847457627118644\n",
            "('concludes', 'by'):1.0\n",
            "('by', 'emphasizing'):0.05555555555555555\n",
            "('emphasizing', 'the'):1.0\n",
            "('the', 'importance'):0.005434782608695652\n",
            "('importance', 'of'):1.0\n",
            "('of', 'rigorous'):0.005681818181818182\n",
            "('rigorous', 'ABSTRACT'):1.0\n",
            "(':', 'Language'):0.05263157894736842\n",
            "('Language', 'is'):0.043478260869565216\n",
            "('is', 'way'):0.018518518518518517\n",
            "('way', 'of'):0.2\n",
            "('of', 'communicating'):0.005681818181818182\n",
            "('communicating', 'your'):1.0\n",
            "('your', 'words'):1.0\n",
            "('words', 'Language'):0.16666666666666666\n",
            "('Language', 'helps'):0.08695652173913043\n",
            "('helps', 'in'):0.5\n",
            "('in', 'understanding'):0.013333333333333334\n",
            "('understanding', 'the'):0.16666666666666666\n",
            "('the', 'world'):0.010869565217391304\n",
            "('world', ','):0.5\n",
            "(',', 'we'):0.06578947368421052\n",
            "('we', 'get'):0.058823529411764705\n",
            "('get', 'a'):1.0\n",
            "('a', 'better'):0.00980392156862745\n",
            "('better', 'insight'):0.5\n",
            "('insight', 'of'):1.0\n",
            "('of', 'the'):0.14772727272727273\n",
            "('world', '.'):0.5\n",
            "('.', 'Language'):0.00684931506849315\n",
            "('helps', 'speakers'):0.5\n",
            "('speakers', 'to'):1.0\n",
            "('be', 'as'):0.038461538461538464\n",
            "('as', 'vague'):0.06666666666666667\n",
            "('vague', 'or'):1.0\n",
            "('or', 'as'):0.058823529411764705\n",
            "('as', 'precise'):0.06666666666666667\n",
            "('precise', 'as'):1.0\n",
            "('as', 'they'):0.06666666666666667\n",
            "('they', 'like'):1.0\n",
            "('like', '.'):0.5\n",
            "('.', 'NLP'):0.00684931506849315\n",
            "('NLP', 'Stands'):0.022727272727272728\n",
            "('Stands', 'for'):1.0\n",
            "('language', 'processing..'):0.011764705882352941\n",
            "('processing..', 'Natural'):1.0\n",
            "('are', 'those'):0.038461538461538464\n",
            "('those', 'languages'):0.5\n",
            "('languages', 'that'):0.16666666666666666\n",
            "('that', 'are'):0.05263157894736842\n",
            "('are', 'spoken'):0.038461538461538464\n",
            "('spoken', 'We'):0.25\n",
            "('We', 'report'):0.041666666666666664\n",
            "('report', 'experiments'):0.5\n",
            "('experiments', 'on'):0.5\n",
            "('the', 'use'):0.016304347826086956\n",
            "('use', 'of'):0.6666666666666666\n",
            "('of', 'standard'):0.005681818181818182\n",
            "('standard', 'natural'):0.3333333333333333\n",
            "(')', 'tools'):0.02127659574468085\n",
            "('tools', 'for'):0.3333333333333333\n",
            "('for', 'the'):0.125\n",
            "('the', 'analysis'):0.005434782608695652\n",
            "('of', 'music'):0.017045454545454544\n",
            "('music', 'lyrics'):0.25\n",
            "('lyrics', '.'):1.0\n",
            "('.', 'A'):0.0136986301369863\n",
            "('A', 'significant'):0.25\n",
            "('significant', 'amount'):0.3333333333333333\n",
            "('amount', 'of'):1.0\n",
            "('music', 'audio'):0.25\n",
            "('audio', 'has'):1.0\n",
            "('has', 'lyrics'):0.08333333333333333\n",
            "('.', 'Lyrics'):0.00684931506849315\n",
            "('Lyrics', 'encode'):1.0\n",
            "('encode', 'an'):0.5\n",
            "('an', 'important'):0.05\n",
            "('important', 'part'):0.3333333333333333\n",
            "('part', 'of'):0.6666666666666666\n",
            "('the', 'semantics'):0.005434782608695652\n",
            "('semantics', 'of'):1.0\n",
            "('a', 'song'):0.00980392156862745\n",
            "('song', ','):1.0\n",
            "(',', 'therefore'):0.006578947368421052\n",
            "('therefore', 'their'):1.0\n",
            "('their', 'analysis'):0.25\n",
            "('analysis', 'complements'):0.09090909090909091\n",
            "('complements', 'that'):1.0\n",
            "('that', 'of'):0.02631578947368421\n",
            "('of', 'acoustic'):0.005681818181818182\n",
            "('acoustic', 'and'):1.0\n",
            "('and', 'cultural'):0.00847457627118644\n",
            "('cultural', 'this'):1.0\n",
            "('this', 'paper'):0.36363636363636365\n",
            "('paper', ','):0.23809523809523808\n",
            "('we', 'will'):0.11764705882352941\n",
            "('will', 'describe'):0.1111111111111111\n",
            "('a', 'simple'):0.00980392156862745\n",
            "('simple', 'rule-based'):1.0\n",
            "('rule-based', 'approach'):1.0\n",
            "('approach', 'to'):0.09090909090909091\n",
            "('to', 'automated'):0.013513513513513514\n",
            "('automated', 'learning'):0.2\n",
            "('learning', 'of'):0.05\n",
            "('of', 'linguistic'):0.022727272727272728\n",
            "('linguistic', 'knowledge'):0.2857142857142857\n",
            "('knowledge', '.'):0.08333333333333333\n",
            "('This', 'approach'):0.034482758620689655\n",
            "('approach', 'has'):0.09090909090909091\n",
            "('has', 'been'):0.25\n",
            "('been', 'shown'):0.07692307692307693\n",
            "('shown', 'for'):0.5\n",
            "('for', 'a'):0.10714285714285714\n",
            "('a', 'number'):0.029411764705882353\n",
            "('number', 'of'):1.0\n",
            "('of', 'tasks'):0.017045454545454544\n",
            "('tasks', 'to'):0.0625\n",
            "('to', 'capture'):0.02702702702702703\n",
            "('capture', 'information'):0.3333333333333333\n",
            "('information', 'in'):0.05263157894736842\n",
            "('a', 'clearer'):0.00980392156862745\n",
            "('clearer', 'and'):1.0\n",
            "('and', 'more'):0.01694915254237288\n",
            "('more', 'direct'):0.1111111111111111\n",
            "('direct', 'fashion'):1.0\n",
            "('fashion', 'without'):1.0\n",
            "('without', 'a'):1.0\n",
            "('a', 'compromise'):0.00980392156862745\n",
            "('compromise', 'in'):1.0\n",
            "('in', 'performance'):0.013333333333333334\n",
            "('performance', '.'):0.5\n",
            "('a', 'detailed'):0.00980392156862745\n",
            "('detailed', 'case'):1.0\n",
            "('case', 'study'):0.5\n",
            "('study', 'of'):1.0\n",
            "('of', 'this'):0.017045454545454544\n",
            "('this', 'learning'):0.045454545454545456\n",
            "('learning', 'method'):0.05\n",
            "('method', 'applied'):0.2\n",
            "('to', 'part'):0.013513513513513514\n",
            "('of', 'speech'):0.005681818181818182\n",
            "('speech', 'tagging'):0.125\n",
            "('tagging', 'This'):0.5\n",
            "('This', 'paper'):0.3448275862068966\n",
            "('paper', 'focuses'):0.047619047619047616\n",
            "('on', 'connectionist'):0.043478260869565216\n",
            "('connectionist', 'models'):1.0\n",
            "('models', 'in'):0.25\n",
            "('We', 'briefly'):0.041666666666666664\n",
            "('briefly', 'present'):0.3333333333333333\n",
            "('present', 'and'):0.25\n",
            "('and', 'discuss'):0.00847457627118644\n",
            "('discuss', 'several'):1.0\n",
            "('several', 'aspects'):0.25\n",
            "('aspects', 'of'):1.0\n",
            "('of', 'high'):0.011363636363636364\n",
            "('high', 'level'):0.6666666666666666\n",
            "('level', 'tasks'):0.5\n",
            "('tasks', 'which'):0.0625\n",
            "('which', 'recently'):0.1111111111111111\n",
            "('recently', 'have'):0.5\n",
            "('been', 'approached'):0.07692307692307693\n",
            "('approached', 'with'):1.0\n",
            "('with', 'connectionism'):0.047619047619047616\n",
            "('connectionism', ','):1.0\n",
            "(',', 'either'):0.006578947368421052\n",
            "('either', 'with'):1.0\n",
            "('with', 'localist'):0.047619047619047616\n",
            "('localist', 'or'):1.0\n",
            "('or', 'parallel'):0.058823529411764705\n",
            "('parallel', 'distributed'):0.5\n",
            "('distributed', 'processing'):1.0\n",
            "('processing', 'models'):0.015625\n",
            "('models', '.'):0.25\n",
            "('.', 'Several'):0.00684931506849315\n",
            "('Several', 'interesting'):1.0\n",
            "('interesting', 'architectures'):1.0\n",
            "('architectures', 'process'):1.0\n",
            "('process', 'of'):0.375\n",
            "('of', 'language'):0.022727272727272728\n",
            "('understanding', '.'):0.16666666666666666\n",
            "('This', 'is'):0.06896551724137931\n",
            "('a', 'new'):0.0392156862745098\n",
            "('new', 'approach'):0.16666666666666666\n",
            "('approach', 'in'):0.09090909090909091\n",
            "('processing', 'based'):0.015625\n",
            "('the', 'deterministic'):0.005434782608695652\n",
            "('deterministic', 'chaotic'):1.0\n",
            "('chaotic', 'behavior'):1.0\n",
            "('behavior', 'of'):1.0\n",
            "('of', 'dynamical'):0.005681818181818182\n",
            "('dynamical', 'systems'):1.0\n",
            "('systems', '.'):0.6\n",
            "('.', '1'):0.0547945205479452\n",
            "('1', 'this'):0.2222222222222222\n",
            "('paper', '('):0.047619047619047616\n",
            "('(', 'see'):0.0196078431372549\n",
            "('see', '['):1.0\n",
            "('[', 'Schank'):0.2\n",
            "('Schank', '86'):1.0\n",
            "('86', ']'):1.0\n",
            "(']', 'for'):0.4\n",
            "('a', 'theoretical'):0.00980392156862745\n",
            "('theoretical', 'discussion'):1.0\n",
            "('discussion', 'and'):1.0\n",
            "('and', '['):0.01694915254237288\n",
            "('[', 'Kass'):0.2\n",
            "('Kass', '86'):1.0\n",
            "(']', 'and'):0.2\n",
            "('[', 'Leake'):0.2\n",
            "('Leake', 'and'):1.0\n",
            "('and', 'Owens'):0.00847457627118644\n",
            "('Owens', '86'):1.0\n",
            "('for', 'brief'):0.017857142857142856\n",
            "('brief', 'discussions'):0.3333333333333333\n",
            "('discussions', 'of'):1.0\n",
            "('a', 'program'):0.00980392156862745\n",
            "('program', 'built'):0.3333333333333333\n",
            "('built', 'around'):0.5\n",
            "('around', 'these'):1.0\n",
            "('these', '.principles'):0.2\n",
            "('.principles', ')'):1.0\n",
            "(')', ';'):0.02127659574468085\n",
            "(';', 'the'):0.3333333333333333\n",
            "('the', 'goal'):0.005434782608695652\n",
            "('goal', 'here'):0.3333333333333333\n",
            "('here', 'is'):0.5\n",
            "('is', 'simply'):0.018518518518518517\n",
            "('simply', 'to'):1.0\n",
            "('to', 'point'):0.013513513513513514\n",
            "('point', 'out'):0.5\n",
            "('out', 'how'):0.3333333333333333\n",
            "('how', 'our'):0.2\n",
            "('our', 'interest'):0.25\n",
            "('interest', 'in'):1.0\n",
            "('processing', 'has'):0.015625\n",
            "('has', 'led'):0.08333333333333333\n",
            "('led', 'us'):1.0\n",
            "('us', 'naturally'):0.5\n",
            "('naturally', ','):0.5\n",
            "('and', 'indeed'):0.00847457627118644\n",
            "('indeed', 'inevitably'):1.0\n",
            "('inevitably', 'Objectives'):1.0\n",
            "('Objectives', 'To'):1.0\n",
            "('To', 'provide'):1.0\n",
            "('provide', 'an'):1.0\n",
            "('an', 'overview'):0.1\n",
            "('overview', 'and'):0.5\n",
            "('and', 'tutorial'):0.00847457627118644\n",
            "('tutorial', 'of'):0.5\n",
            "(')', 'and'):0.1276595744680851\n",
            "('and', 'modern'):0.00847457627118644\n",
            "('modern', 'NLP-system'):1.0\n",
            "('NLP-system', 'design'):1.0\n",
            "('design', '.'):0.25\n",
            "('.', 'Target'):0.00684931506849315\n",
            "('Target', 'audience'):1.0\n",
            "('audience', 'This'):1.0\n",
            "('This', 'tutorial'):0.034482758620689655\n",
            "('tutorial', 'targets'):0.5\n",
            "('targets', 'the'):1.0\n",
            "('the', 'medical'):0.005434782608695652\n",
            "('medical', 'informatics'):1.0\n",
            "('informatics', 'generalist'):1.0\n",
            "('generalist', 'who'):1.0\n",
            "('who', 'has'):1.0\n",
            "('has', 'limited'):0.08333333333333333\n",
            "('limited', 'acquaintance'):0.25\n",
            "('acquaintance', 'with'):1.0\n",
            "('the', 'principles'):0.005434782608695652\n",
            "('principles', 'behind'):0.5\n",
            "('behind', 'NLP'):1.0\n",
            "('NLP', 'and/or'):0.022727272727272728\n",
            "('and/or', 'limited'):1.0\n",
            "('limited', 'knowledge'):0.25\n",
            "('knowledge', 'of'):0.08333333333333333\n",
            "('the', 'current'):0.021739130434782608\n",
            "('current', 'state'):0.2857142857142857\n",
            "('state', 'This'):0.2\n",
            "('paper', 'briefly'):0.047619047619047616\n",
            "('briefly', 'describes'):0.3333333333333333\n",
            "('describes', 'the'):0.5\n",
            "('current', 'implementation'):0.14285714285714285\n",
            "('implementation', 'status'):0.5\n",
            "('status', 'of'):1.0\n",
            "('of', 'an'):0.017045454545454544\n",
            "('an', 'intelligent'):0.05\n",
            "('intelligent', 'information'):0.5\n",
            "('information', 'retrieval'):0.21052631578947367\n",
            "('retrieval', 'system'):0.2222222222222222\n",
            "('system', ','):0.23076923076923078\n",
            "(',', 'MARIE'):0.006578947368421052\n",
            "('MARIE', ','):1.0\n",
            "(',', 'that'):0.006578947368421052\n",
            "('that', 'employs'):0.02631578947368421\n",
            "('employs', 'natural'):1.0\n",
            "('processing', 'techniques'):0.046875\n",
            "('techniques', '.'):0.14285714285714285\n",
            "('.', 'Descriptive'):0.00684931506849315\n",
            "('Descriptive', 'captions'):1.0\n",
            "('captions', 'are'):1.0\n",
            "('are', 'used'):0.038461538461538464\n",
            "('to', 'iden-'):0.013513513513513514\n",
            "('iden-', 'tify'):1.0\n",
            "('tify', 'photographic'):1.0\n",
            "('photographic', 'images'):1.0\n",
            "('images', 'concerning'):0.5\n",
            "('concerning', 'various'):0.5\n",
            "('various', 'military'):0.125\n",
            "('military', 'projects'):1.0\n",
            "('projects', '.'):0.5\n",
            "('The', 'captions'):0.038461538461538464\n",
            "('are', 'parsed'):0.038461538461538464\n",
            "('parsed', 'based'):1.0\n",
            "('based', 'and'):0.125\n",
            "('and', 'literature'):0.00847457627118644\n",
            "('literature', 'resources'):1.0\n",
            "('resources', '.'):0.4\n",
            "('We', 'describe'):0.16666666666666666\n",
            "('describe', 'here'):0.1111111111111111\n",
            "('here', 'a'):0.5\n",
            "('a', 'system'):0.00980392156862745\n",
            "('for', 'agent'):0.017857142857142856\n",
            "('agent', 'directed'):1.0\n",
            "('directed', 'natural'):1.0\n",
            "('processing', 'to'):0.046875\n",
            "('to', 'extract'):0.04054054054054054\n",
            "('extract', 'information'):0.25\n",
            "('information', 'from'):0.10526315789473684\n",
            "('from', 'journal'):0.05555555555555555\n",
            "('journal', 'articles'):1.0\n",
            "('articles', '.'):1.0\n",
            "('.', 'An'):0.00684931506849315\n",
            "('An', 'interface'):0.5\n",
            "('interface', 'was'):0.5\n",
            "('was', 'developed'):1.0\n",
            "('developed', 'to'):0.2\n",
            "('to', 'permit'):0.013513513513513514\n",
            "('permit', 'curation'):1.0\n",
            "('curation', 'of'):1.0\n",
            "('the', 'NLP'):0.005434782608695652\n",
            "('NLP', 'results'):0.022727272727272728\n",
            "('results', 'and'):0.14285714285714285\n",
            "('and', 'deposition'):0.00847457627118644\n",
            "('deposition', 'of'):1.0\n",
            "('of', 'accepted'):0.005681818181818182\n",
            "('accepted', 'results'):1.0\n",
            "('results', 'into'):0.14285714285714285\n",
            "('into', 'a'):0.5\n",
            "('base', '.'):0.5\n",
            "('.', 'Motivation'):0.00684931506849315\n",
            "('Motivation', ':'):1.0\n",
            "(':', 'The'):0.05263157894736842\n",
            "('The', 'advent'):0.038461538461538464\n",
            "('advent', 'of'):1.0\n",
            "('high', 'to'):0.3333333333333333\n",
            "('to', 'evaluation'):0.013513513513513514\n",
            "('evaluation', 'in'):0.25\n",
            "('in', 'speech'):0.013333333333333334\n",
            "('speech', 'processing'):0.125\n",
            "('.', 'Part'):0.00684931506849315\n",
            "('Part', '2'):1.0\n",
            "('2', 'surveys'):1.0\n",
            "('surveys', 'significant'):1.0\n",
            "('significant', 'evaluation'):0.3333333333333333\n",
            "('evaluation', 'work'):0.125\n",
            "('work', 'done'):0.14285714285714285\n",
            "('done', 'so'):1.0\n",
            "('so', 'far'):0.6666666666666666\n",
            "('far', ','):0.5\n",
            "(',', 'for'):0.006578947368421052\n",
            "('for', 'instance'):0.017857142857142856\n",
            "('instance', 'in'):1.0\n",
            "('in', 'machine'):0.013333333333333334\n",
            "('translation', ','):0.5\n",
            "('and', 'discusses'):0.00847457627118644\n",
            "('discusses', 'the'):1.0\n",
            "('the', 'particular'):0.005434782608695652\n",
            "('particular', 'problems'):0.2\n",
            "('problems', 'of'):0.3333333333333333\n",
            "('of', 'generic'):0.005681818181818182\n",
            "('generic', 'system'):0.3333333333333333\n",
            "('system', 'evaluation'):0.07692307692307693\n",
            "('evaluation', '.'):0.125\n",
            "('The', 'conclusion'):0.038461538461538464\n",
            "('conclusion', 'is'):1.0\n",
            "('is', 'that'):0.018518518518518517\n",
            "('that', 'evaluation'):0.02631578947368421\n",
            "('evaluation', 'strategies'):0.25\n",
            "('strategies', 'and'):0.5\n",
            "('and', 'techniques'):0.00847457627118644\n",
            "('techniques', 'for'):0.21428571428571427\n",
            "('for', 'NLP'):0.017857142857142856\n",
            "('NLP', 'need'):0.022727272727272728\n",
            "('need', 'much'):0.16666666666666666\n",
            "('much', 'more'):0.5\n",
            "('more', 'development'):0.1111111111111111\n",
            "('development', ','):0.1111111111111111\n",
            "('particular', 'similar'):0.2\n",
            "('similar', 'to'):0.5\n",
            "('humans', 'intuitively'):0.25\n",
            "('intuitively', 'do'):0.5\n",
            "('do', 'in'):0.3333333333333333\n",
            "('in', 'order'):0.013333333333333334\n",
            "('order', 'to'):1.0\n",
            "('to', 'eliminate'):0.013513513513513514\n",
            "('eliminate', 'noisy'):1.0\n",
            "('noisy', 'content'):1.0\n",
            "('content', '.'):1.0\n",
            "('In', 'this'):0.47058823529411764\n",
            "('we', 'describe'):0.11764705882352941\n",
            "('a', 'combination'):0.00980392156862745\n",
            "('combination', 'of'):1.0\n",
            "('of', 'HTML'):0.005681818181818182\n",
            "('HTML', 'DOM'):1.0\n",
            "('DOM', 'analysis'):1.0\n",
            "('analysis', 'and'):0.09090909090909091\n",
            "('and', 'Natural'):0.01694915254237288\n",
            "(')', 'techniques'):0.0425531914893617\n",
            "('for', 'automated'):0.017857142857142856\n",
            "('automated', 'extractions'):0.2\n",
            "('extractions', 'of'):1.0\n",
            "('of', 'main'):0.005681818181818182\n",
            "('main', 'article'):1.0\n",
            "('article', 'with'):0.3333333333333333\n",
            "('with', 'associated'):0.047619047619047616\n",
            "('associated', 'images'):1.0\n",
            "('images', 'from'):0.5\n",
            "('from', 'web'):0.05555555555555555\n",
            "('web', 'pages'):1.0\n",
            "('pages', '.'):1.0\n",
            "('.', 'Abstract'):0.02054794520547945\n",
            "('Abstract', '--'):0.07692307692307693\n",
            "('--', 'Natural'):0.07142857142857142\n",
            "('Processing', 'is'):0.05\n",
            "('a', 'theoretically'):0.00980392156862745\n",
            "('theoretically', 'motivated'):1.0\n",
            "('motivated', 'range'):1.0\n",
            "('range', 'of'):1.0\n",
            "('of', 'computational'):0.005681818181818182\n",
            "('computational', 'techniques'):0.2\n",
            "('for', 'analysing'):0.017857142857142856\n",
            "('analysing', 'and'):1.0\n",
            "('and', 'representing'):0.00847457627118644\n",
            "('representing', 'naturally'):1.0\n",
            "('naturally', 'occurring'):0.5\n",
            "('occurring', 'texts'):1.0\n",
            "('texts', 'at'):0.5\n",
            "('at', 'one'):0.14285714285714285\n",
            "('one', 'or'):0.2\n",
            "('or', 'more'):0.058823529411764705\n",
            "('more', 'levels'):0.1111111111111111\n",
            "('linguistic', 'analysis'):0.14285714285714285\n",
            "('analysis', 'for'):0.09090909090909091\n",
            "('the', 'purpose'):0.005434782608695652\n",
            "('purpose', 'of'):0.5\n",
            "('of', 'achieving'):0.005681818181818182\n",
            "('achieving', 'human-like'):1.0\n",
            "('human-like', 'language'):1.0\n",
            "('processing', 'for'):0.03125\n",
            "('a', 'range'):0.00980392156862745\n",
            "('tasks', 'This'):0.0625\n",
            "('paper', 'reviews'):0.09523809523809523\n",
            "('reviews', 'the'):1.0\n",
            "('the', 'processes'):0.010869565217391304\n",
            "('processes', 'involved'):0.25\n",
            "('involved', 'in'):1.0\n",
            "('in', 'Natural'):0.02666666666666667\n",
            "(')', '.'):0.0851063829787234\n",
            "('It', 'then'):0.2\n",
            "('then', 'demonstrates'):0.2\n",
            "('demonstrates', 'the'):1.0\n",
            "('the', 'various'):0.005434782608695652\n",
            "('various', 'kinds'):0.125\n",
            "('kinds', 'of'):1.0\n",
            "('of', 'choices'):0.005681818181818182\n",
            "('choices', 'that'):1.0\n",
            "('that', 'need'):0.05263157894736842\n",
            "('need', 'be'):0.16666666666666666\n",
            "('be', 'taken'):0.038461538461538464\n",
            "('taken', 'during'):0.5\n",
            "('during', 'the'):0.6666666666666666\n",
            "('the', 'execution'):0.005434782608695652\n",
            "('execution', 'of'):0.5\n",
            "('the', 'word'):0.010869565217391304\n",
            "('word', 'morphology'):0.14285714285714285\n",
            "('morphology', ','):1.0\n",
            "(',', 'the'):0.019736842105263157\n",
            "('the', 'syntactic'):0.005434782608695652\n",
            "('syntactic', 'text'):0.16666666666666666\n",
            "('text', 'analysis'):0.2\n",
            "('analysis', ','):0.18181818181818182\n",
            "(',', 'or'):0.013157894736842105\n",
            "('or', 'text'):0.058823529411764705\n",
            "('text', 'generation'):0.1\n",
            "('generation', 'components'):0.5\n",
            "('components', '.'):0.5\n",
            "('It', 'compares'):0.2\n",
            "('compares', 'the'):1.0\n",
            "('the', 'time'):0.005434782608695652\n",
            "('time', 'complexity'):0.5\n",
            "('complexity', 'This'):0.25\n",
            "('This', 'article'):0.06896551724137931\n",
            "('article', 'focusses'):0.3333333333333333\n",
            "('focusses', 'on'):1.0\n",
            "('the', 'derivation'):0.005434782608695652\n",
            "('derivation', 'of'):1.0\n",
            "('of', 'large'):0.005681818181818182\n",
            "('large', 'lexicons'):0.5\n",
            "('lexicons', 'for'):1.0\n",
            "('describe', 'the'):0.2222222222222222\n",
            "('development', 'of'):0.3333333333333333\n",
            "('a', 'dictionary'):0.00980392156862745\n",
            "('dictionary', 'support'):0.5\n",
            "('support', 'environment'):0.5\n",
            "('environment', 'linking'):0.5\n",
            "('linking', 'a'):1.0\n",
            "('a', 'restructured'):0.00980392156862745\n",
            "('restructured', 'version'):1.0\n",
            "('version', 'of'):1.0\n",
            "('the', 'Longman'):0.005434782608695652\n",
            "('Longman', 'Dictionary'):1.0\n",
            "('Dictionary', 'of'):1.0\n",
            "('of', 'Contemporary'):0.005681818181818182\n",
            "('Contemporary', 'English'):1.0\n",
            "('English', 'to'):0.5\n",
            "('to', 'natural'):0.02702702702702703\n",
            "('processing', 'systems'):0.0625\n",
            "('The', 'process'):0.038461538461538464\n",
            "('process', 'We'):0.125\n",
            "('We', 'introduce'):0.041666666666666664\n",
            "('introduce', 'a'):1.0\n",
            "('for', 'analyzing'):0.017857142857142856\n",
            "('analyzing', 'the'):0.5\n",
            "('the', 'complexity'):0.005434782608695652\n",
            "('complexity', 'of'):0.5\n",
            "('tasks', ','):0.25\n",
            "('and', 'for'):0.01694915254237288\n",
            "('for', 'predicting'):0.017857142857142856\n",
            "('predicting', 'the'):1.0\n",
            "('the', 'difficulty'):0.005434782608695652\n",
            "('difficulty', 'new'):1.0\n",
            "('new', 'NLP'):0.16666666666666666\n",
            "('NLP', 'tasks'):0.06818181818181818\n",
            "('tasks', '.'):0.25\n",
            "('.', 'Our'):0.0136986301369863\n",
            "('Our', 'complexity'):0.5\n",
            "('complexity', 'measures'):0.25\n",
            "('measures', 'are'):0.6666666666666666\n",
            "('are', 'derived'):0.038461538461538464\n",
            "('derived', 'from'):1.0\n",
            "('from', 'the'):0.05555555555555555\n",
            "('the', 'Kolmogorov'):0.005434782608695652\n",
            "('Kolmogorov', 'complexity'):1.0\n",
            "('a', 'class'):0.00980392156862745\n",
            "('class', 'of'):0.5\n",
            "('of', 'automata'):0.005681818181818182\n",
            "('automata', 'â€”'):0.5\n",
            "('â€”', 'meaning'):1.0\n",
            "('meaning', 'automata'):0.5\n",
            "('automata', ','):0.5\n",
            "(',', 'whose'):0.006578947368421052\n",
            "('whose', 'purpose'):1.0\n",
            "('purpose', 'is'):0.5\n",
            "('is', 'to'):0.1111111111111111\n",
            "('extract', 'relevant'):0.25\n",
            "('relevant', 'pieces'):0.3333333333333333\n",
            "('pieces', ','):1.0\n",
            "(',', 'sounds'):0.006578947368421052\n",
            "('sounds', ','):1.0\n",
            "(',', 'text'):0.02631578947368421\n",
            "('text', 'and'):0.1\n",
            "('and', 'motion'):0.00847457627118644\n",
            "('motion', '.'):1.0\n",
            "('The', 'techniques'):0.038461538461538464\n",
            "('techniques', 'developed'):0.07142857142857142\n",
            "('developed', 'from'):0.2\n",
            "('from', 'deep'):0.05555555555555555\n",
            "('deep', 'learning'):1.0\n",
            "('learning', 'research'):0.05\n",
            "('research', 'have'):0.08333333333333333\n",
            "('have', 'already'):0.08333333333333333\n",
            "('already', 'been'):1.0\n",
            "('been', 'impacting'):0.07692307692307693\n",
            "('impacting', 'the'):1.0\n",
            "('the', 'research'):0.010869565217391304\n",
            "('research', 'of'):0.08333333333333333\n",
            "('language', 'process'):0.011764705882352941\n",
            "('process', '.'):0.125\n",
            "('the', 'recent'):0.005434782608695652\n",
            "('recent', 'research'):0.5\n",
            "('research', 'on'):0.08333333333333333\n",
            "('on', 'deep'):0.043478260869565216\n",
            "('learning', ','):0.1\n",
            "(',', 'its'):0.006578947368421052\n",
            "('its', 'applications'):0.3333333333333333\n",
            "('applications', 'and'):0.09090909090909091\n",
            "('and', 'recent'):0.00847457627118644\n",
            "('recent', 'development'):0.3333333333333333\n",
            "('development', 'in'):0.2222222222222222\n",
            "('1', 'This'):0.1111111111111111\n",
            "('is', 'an'):0.07407407407407407\n",
            "('an', 'author-produced'):0.05\n",
            "('author-produced', 'version'):1.0\n",
            "('a', 'paper'):0.00980392156862745\n",
            "('paper', 'published'):0.047619047619047616\n",
            "('published', 'in'):1.0\n",
            "('in', 'The'):0.013333333333333334\n",
            "('The', 'Abstractâ€”Natural'):0.038461538461538464\n",
            "('Abstractâ€”Natural', 'language'):0.5\n",
            "('the', 'application'):0.02717391304347826\n",
            "('application', 'of'):0.8\n",
            "('of', 'automated'):0.005681818181818182\n",
            "('automated', 'parsing'):0.2\n",
            "('parsing', 'and'):0.25\n",
            "('learning', 'techniques'):0.1\n",
            "('techniques', 'to'):0.14285714285714285\n",
            "('to', 'analyze'):0.013513513513513514\n",
            "('analyze', 'standard'):1.0\n",
            "('standard', 'text'):0.3333333333333333\n",
            "('text', '.'):0.1\n",
            "('.', 'Applications'):0.00684931506849315\n",
            "('Applications', 'of'):1.0\n",
            "('of', 'NLP'):0.022727272727272728\n",
            "('NLP', 'to'):0.045454545454545456\n",
            "('to', 'requirements'):0.013513513513513514\n",
            "('requirements', 'engineering'):0.2\n",
            "('engineering', 'include'):0.5\n",
            "('include', 'extraction'):0.5\n",
            "('extraction', 'of'):0.3333333333333333\n",
            "('of', 'ontologies'):0.005681818181818182\n",
            "('ontologies', 'from'):1.0\n",
            "('from', 'a'):0.16666666666666666\n",
            "('a', 'requirements'):0.00980392156862745\n",
            "('requirements', 'specification'):0.2\n",
            "('specification', ','):1.0\n",
            "('and', 'use'):0.01694915254237288\n",
            "('to', 'verify'):0.013513513513513514\n",
            "('verify', 'the'):1.0\n",
            "('the', 'consistency'):0.005434782608695652\n",
            "('consistency', 'statistical'):1.0\n",
            "('statistical', 'baseline'):0.14285714285714285\n",
            "('baseline', 'including'):1.0\n",
            "('including', ':'):0.125\n",
            "(':', 'the'):0.10526315789473684\n",
            "('the', 'forgiving'):0.005434782608695652\n",
            "('forgiving', 'nature'):1.0\n",
            "('nature', 'but'):1.0\n",
            "('but', 'broad'):0.16666666666666666\n",
            "('broad', 'coverage'):0.3333333333333333\n",
            "('coverage', 'of'):1.0\n",
            "('the', 'typical'):0.005434782608695652\n",
            "('typical', 'retrieval'):1.0\n",
            "('retrieval', 'task'):0.1111111111111111\n",
            "('task', ';'):0.25\n",
            "('the', 'lack'):0.005434782608695652\n",
            "('lack', 'of'):1.0\n",
            "('of', 'good'):0.005681818181818182\n",
            "('good', 'weighting'):0.5\n",
            "('weighting', 'schemes'):0.5\n",
            "('schemes', 'for'):1.0\n",
            "('for', 'compound'):0.017857142857142856\n",
            "('compound', 'index'):0.3333333333333333\n",
            "('index', 'terms'):1.0\n",
            "('terms', ';'):1.0\n",
            "(';', 'and'):0.16666666666666666\n",
            "('the', 'implicit'):0.005434782608695652\n",
            "('implicit', 'linguistic'):0.5\n",
            "('linguistic', 'processing'):0.14285714285714285\n",
            "('processing', 'inherent'):0.015625\n",
            "('inherent', 'in'):1.0\n",
            "('the', 'statistical'):0.005434782608695652\n",
            "('statistical', 'methods'):0.14285714285714285\n",
            "('methods', '.'):0.3333333333333333\n",
            "('techniques', 'may'):0.07142857142857142\n",
            "('may', 'be'):0.3333333333333333\n",
            "('be', 'more'):0.038461538461538464\n",
            "('more', 'important'):0.1111111111111111\n",
            "('important', 'Work'):0.3333333333333333\n",
            "('Work', 'in'):1.0\n",
            "('in', 'computational'):0.02666666666666667\n",
            "('computational', 'linguistics'):0.4\n",
            "('linguistics', 'began'):0.2\n",
            "('began', 'very'):1.0\n",
            "('very', 'soon'):0.5\n",
            "('soon', 'after'):1.0\n",
            "('after', 'the'):1.0\n",
            "('the', 'first'):0.005434782608695652\n",
            "('first', 'computers'):0.3333333333333333\n",
            "('computers', '('):0.3333333333333333\n",
            "('(', 'Booth'):0.0196078431372549\n",
            "('Booth', ','):1.0\n",
            "(',', 'Brandwood'):0.006578947368421052\n",
            "('Brandwood', 'and'):1.0\n",
            "('and', 'Cleave'):0.00847457627118644\n",
            "('Cleave', '1958'):1.0\n",
            "('1958', ')'):1.0\n",
            "(',', 'yet'):0.006578947368421052\n",
            "('yet', 'in'):0.5\n",
            "('the', 'intervening'):0.005434782608695652\n",
            "('intervening', 'four'):1.0\n",
            "('four', 'decades'):1.0\n",
            "('decades', 'there'):1.0\n",
            "('there', 'has'):1.0\n",
            "('been', 'a'):0.07692307692307693\n",
            "('a', 'pervasive'):0.00980392156862745\n",
            "('pervasive', 'feeling'):1.0\n",
            "('feeling', 'that'):1.0\n",
            "('that', 'progress'):0.02631578947368421\n",
            "('progress', 'in'):1.0\n",
            "('in', 'computer'):0.013333333333333334\n",
            "('computer', 'understanding'):1.0\n",
            "('understanding', 'of'):0.3333333333333333\n",
            "('language', 'has'):0.011764705882352941\n",
            "('has', 'not'):0.08333333333333333\n",
            "('not', 'been'):0.07142857142857142\n",
            "('been', 'commensurate'):0.07692307692307693\n",
            "('commensurate', 'the'):1.0\n",
            "('the', 'voice'):0.005434782608695652\n",
            "('voice', 'recognition'):1.0\n",
            "('recognition', 'for'):0.08333333333333333\n",
            "('a', 'natural'):0.0196078431372549\n",
            "('language', '('):0.011764705882352941\n",
            "('(', 'Tamil'):0.0196078431372549\n",
            "('Tamil', ')'):1.0\n",
            "(')', 'by'):0.02127659574468085\n",
            "('by', 'combining'):0.05555555555555555\n",
            "('combining', 'the'):1.0\n",
            "('the', 'digital'):0.005434782608695652\n",
            "('digital', 'and'):0.3333333333333333\n",
            "('and', 'mathematical'):0.00847457627118644\n",
            "('mathematical', 'knowledge'):0.5\n",
            "('knowledge', 'using'):0.08333333333333333\n",
            "('using', 'MFCC'):0.09090909090909091\n",
            "('MFCC', 'and'):1.0\n",
            "('and', 'DTW'):0.00847457627118644\n",
            "('DTW', 'to'):1.0\n",
            "('extract', 'and'):0.25\n",
            "('and', 'match'):0.00847457627118644\n",
            "('match', 'the'):1.0\n",
            "('the', 'features'):0.005434782608695652\n",
            "('features', 'to'):0.5\n",
            "('to', 'improve'):0.02702702702702703\n",
            "('improve', 'the'):0.5\n",
            "('the', 'accuracy'):0.005434782608695652\n",
            "('accuracy', 'for'):1.0\n",
            "('for', 'better'):0.017857142857142856\n",
            "('better', 'performance'):0.5\n",
            "('Abstract', ':'):0.15384615384615385\n",
            "(':', 'Testing'):0.05263157894736842\n",
            "('Testing', 'against'):1.0\n",
            "('against', 'natural'):1.0\n",
            "('language', 'requirements'):0.011764705882352941\n",
            "('requirements', 'is'):0.2\n",
            "('the', 'standard'):0.005434782608695652\n",
            "('standard', 'approach'):0.3333333333333333\n",
            "('for', 'system'):0.017857142857142856\n",
            "('system', 'and'):0.07692307692307693\n",
            "('and', 'acceptance'):0.00847457627118644\n",
            "('acceptance', 'testing'):1.0\n",
            "('testing', '.'):1.0\n",
            "('This', 'test'):0.034482758620689655\n",
            "('test', 'is'):0.5\n",
            "('is', 'often'):0.018518518518518517\n",
            "('often', 'performed'):0.5\n",
            "('performed', 'by'):1.0\n",
            "('by', 'an'):0.05555555555555555\n",
            "('an', 'independent'):0.05\n",
            "('independent', 'test'):0.5\n",
            "('test', 'organization'):0.5\n",
            "('organization', 'unfamiliar'):1.0\n",
            "('unfamiliar', 'with'):1.0\n",
            "('application', 'area'):0.2\n",
            "('area', '.'):1.0\n",
            "('The', 'only'):0.038461538461538464\n",
            "('only', 'things'):0.5\n",
            "('things', 'the'):1.0\n",
            "('the', 'testers'):0.005434782608695652\n",
            "('testers', 'have'):1.0\n",
            "('have', 'to'):0.08333333333333333\n",
            "('to', 'go'):0.013513513513513514\n",
            "('go', 'by'):1.0\n",
            "('by', 'are'):0.05555555555555555\n",
            "('are', 'the'):0.07692307692307693\n",
            "('the', 'written'):0.005434782608695652\n",
            "('written', 'requirements'):1.0\n",
            "('requirements', '.'):0.2\n",
            "('.', 'So'):0.0136986301369863\n",
            "('So', 'Abstract'):0.5\n",
            "('found', 'conversational'):0.125\n",
            "('conversational', 'partners'):1.0\n",
            "('partners', '.'):1.0\n",
            "('.', 'But'):0.00684931506849315\n",
            "('But', 'it'):1.0\n",
            "('it', 'also'):0.1\n",
            "('also', 'provides'):0.2\n",
            "('provides', 'us'):0.5\n",
            "('us', 'with'):0.5\n",
            "('with', 'information'):0.047619047619047616\n",
            "('information', 'about'):0.15789473684210525\n",
            "('about', 'being'):0.3333333333333333\n",
            "('being', 'creative'):0.5\n",
            "('creative', ','):1.0\n",
            "(',', 'making'):0.006578947368421052\n",
            "('making', 'associations'):1.0\n",
            "('associations', ','):1.0\n",
            "(',', 'storytelling'):0.006578947368421052\n",
            "('storytelling', 'and'):1.0\n",
            "('and', 'language'):0.00847457627118644\n",
            "('language', 'use'):0.011764705882352941\n",
            "('use', '.'):0.08333333333333333\n",
            "('.', 'Many'):0.00684931506849315\n",
            "('Many', 'more'):0.3333333333333333\n",
            "('more', 'subtleties'):0.1111111111111111\n",
            "('subtleties', 'in'):1.0\n",
            "('in', 'face-to-face'):0.013333333333333334\n",
            "('face-to-face', 'and'):0.5\n",
            "('and', 'multiparty'):0.00847457627118644\n",
            "('multiparty', 'interaction'):1.0\n",
            "('interaction', 'can'):1.0\n",
            "('be', 'added'):0.038461538461538464\n",
            "('added', ','):1.0\n",
            "(',', 'such'):0.013157894736842105\n",
            "('such', 'as'):0.75\n",
            "('as', 'using'):0.06666666666666667\n",
            "('using', 'humor'):0.09090909090909091\n",
            "('humor', 'to'):1.0\n",
            "('to', 'persuade'):0.013513513513513514\n",
            "('persuade', 'and'):1.0\n",
            "('and', 'dominate'):0.00847457627118644\n",
            "('dominate', ','):1.0\n",
            "(',', 'to'):0.02631578947368421\n",
            "('to', 'soften'):0.013513513513513514\n",
            "('soften', 'or'):1.0\n",
            "('or', 'avoid'):0.058823529411764705\n",
            "('avoid', 'a'):0.3333333333333333\n",
            "('a', 'face'):0.00980392156862745\n",
            "('face', 'threatening'):1.0\n",
            "('threatening', 'act'):1.0\n",
            "('act', 'Abstract'):1.0\n",
            "('found', 'In'):0.25\n",
            "('In', 'recent'):0.058823529411764705\n",
            "('recent', 'years'):0.16666666666666666\n",
            "('years', ','):0.25\n",
            "(',', 'machine'):0.02631578947368421\n",
            "('learning', '('):0.05\n",
            "('(', 'ML'):0.0392156862745098\n",
            "('ML', ')'):1.0\n",
            "(')', 'has'):0.02127659574468085\n",
            "('used', 'more'):0.09090909090909091\n",
            "('more', 'and'):0.1111111111111111\n",
            "('more', 'to'):0.1111111111111111\n",
            "('to', 'solve'):0.02702702702702703\n",
            "('solve', 'complex'):0.5\n",
            "('complex', 'tasks'):1.0\n",
            "('tasks', 'in'):0.0625\n",
            "('in', 'different'):0.02666666666666667\n",
            "('different', 'disciplines'):0.25\n",
            "('disciplines', ','):1.0\n",
            "(',', 'ranging'):0.006578947368421052\n",
            "('ranging', 'from'):1.0\n",
            "('from', 'Data'):0.05555555555555555\n",
            "('Data', 'Mining'):1.0\n",
            "('Mining', 'to'):1.0\n",
            "('to', 'Information'):0.013513513513513514\n",
            "('Information', 'We'):0.3333333333333333\n",
            "('We', 'argue'):0.041666666666666664\n",
            "('argue', 'that'):0.6666666666666666\n",
            "('that', 'manual'):0.02631578947368421\n",
            "('manual', 'and'):0.5\n",
            "('and', 'automatic'):0.00847457627118644\n",
            "('automatic', 'thesauruses'):1.0\n",
            "('thesauruses', 'are'):0.3333333333333333\n",
            "('are', 'alternative'):0.038461538461538464\n",
            "('alternative', 'resources'):1.0\n",
            "('resources', 'for'):0.2\n",
            "('the', 'same'):0.016304347826086956\n",
            "('same', 'NLP'):0.3333333333333333\n",
            "('This', 'involves'):0.034482758620689655\n",
            "('involves', 'the'):0.5\n",
            "('the', 'radical'):0.005434782608695652\n",
            "('radical', 'step'):1.0\n",
            "('step', 'of'):1.0\n",
            "('of', 'interpreting'):0.005681818181818182\n",
            "('interpreting', 'manual'):1.0\n",
            "('manual', 'thesauruses'):0.5\n",
            "('thesauruses', 'as'):0.3333333333333333\n",
            "('as', 'classifications'):0.06666666666666667\n",
            "('classifications', 'of'):1.0\n",
            "('of', 'words'):0.005681818181818182\n",
            "('words', 'rather'):0.16666666666666666\n",
            "('than', 'word'):0.25\n",
            "('word', 'senses'):0.14285714285714285\n",
            "('senses', ':'):0.5\n",
            "('the', 'case'):0.005434782608695652\n",
            "('case', 'for'):0.5\n",
            "('for', 'this'):0.017857142857142856\n",
            "('this', 'is'):0.045454545454545456\n",
            "('is', 'made'):0.018518518518518517\n",
            "('made', '.'):0.3333333333333333\n",
            "('The', 'range'):0.038461538461538464\n",
            "('of', 'roles'):0.005681818181818182\n",
            "('roles', 'for'):0.5\n",
            "('for', 'thesauruses'):0.017857142857142856\n",
            "('thesauruses', 'within'):0.3333333333333333\n",
            "('within', 'NLP'):0.4\n",
            "('NLP', 'is'):0.022727272727272728\n",
            "('is', 'briefly'):0.018518518518518517\n",
            "('briefly', 'presented'):0.3333333333333333\n",
            "('presented', 'and'):0.5\n",
            "('the', 'WASPS'):0.005434782608695652\n",
            "('WASPS', 'thesaurus'):1.0\n",
            "('thesaurus', 'is'):0.5\n",
            "('is', 'introduced'):0.018518518518518517\n",
            "('introduced', '.'):0.5\n",
            "('.', 'Thesaurus'):0.00684931506849315\n",
            "('Thesaurus', 'evaluation'):1.0\n",
            "('evaluation', 'is'):0.125\n",
            "('is', 'now'):0.018518518518518517\n",
            "('now', 'becoming'):1.0\n",
            "('becoming', 'urgent'):1.0\n",
            "('urgent', '.'):1.0\n",
            "('A', 'range'):0.25\n",
            "('of', 'evaluation'):0.005681818181818182\n",
            "('strategies', ','):0.5\n",
            "(',', 'all'):0.013157894736842105\n",
            "('all', 'embedded'):0.14285714285714285\n",
            "('embedded', 'within'):1.0\n",
            "(',', 'is'):0.006578947368421052\n",
            "('is', 'proposed'):0.018518518518518517\n",
            "('proposed', '.'):1.0\n",
            "('.', 'Introduction'):0.00684931506849315\n",
            "('Introduction', 'Patterns'):0.2\n",
            "('Patterns', 'in'):0.5\n",
            "('in', 'music'):0.013333333333333334\n",
            "('music', 'have'):0.25\n",
            "('been', 'the'):0.07692307692307693\n",
            "('the', 'object'):0.005434782608695652\n",
            "('object', 'of'):0.5\n",
            "('of', 'intensive'):0.005681818181818182\n",
            "('intensive', 'studies'):1.0\n",
            "('studies', 'in'):0.5\n",
            "('the', 'past'):0.010869565217391304\n",
            "('past', 'years'):0.5\n",
            "('years', '.'):0.25\n",
            "('.', '\\\\One'):0.00684931506849315\n",
            "('\\\\One', 'of'):1.0\n",
            "('the', 'purposes'):0.005434782608695652\n",
            "('purposes', 'of'):0.5\n",
            "('of', 'analyzing'):0.005681818181818182\n",
            "('analyzing', 'musical'):0.5\n",
            "('musical', 'structure'):0.3333333333333333\n",
            "('structure', 'and'):0.25\n",
            "('and', 'form'):0.00847457627118644\n",
            "('form', 'is'):0.5\n",
            "('to', 'discover'):0.013513513513513514\n",
            "('discover', 'the'):1.0\n",
            "('the', 'patterns'):0.005434782608695652\n",
            "('patterns', 'that'):0.3333333333333333\n",
            "('are', 'explicit'):0.038461538461538464\n",
            "('explicit', 'or'):1.0\n",
            "('or', 'implicit'):0.058823529411764705\n",
            "('implicit', 'in'):0.5\n",
            "('in', 'musical'):0.013333333333333334\n",
            "('musical', 'works'):0.3333333333333333\n",
            "('works', \"''\"):0.5\n",
            "(\"''\", 'Simon'):0.2\n",
            "('Simon', '['):1.0\n",
            "('[', '13'):0.2\n",
            "('13', ']'):1.0\n",
            "(']', '.'):0.2\n",
            "('.', 'Patterns'):0.00684931506849315\n",
            "('Patterns', 'comprise'):0.5\n",
            "('comprise', 'periodicity'):1.0\n",
            "('periodicity', ','):1.0\n",
            "(',', 'make'):0.006578947368421052\n",
            "('make', 'use'):1.0\n",
            "('of', 'alphabets'):0.005681818181818182\n",
            "('alphabets', ','):1.0\n",
            "(',', 'can'):0.006578947368421052\n",
            "('be', 'compound'):0.038461538461538464\n",
            "('compound', '('):0.3333333333333333\n",
            "('(', 'made'):0.0196078431372549\n",
            "('made', 'up'):0.3333333333333333\n",
            "('up', 'of'):1.0\n",
            "('of', 'subpatterns'):0.005681818181818182\n",
            "('subpatterns', ')'):1.0\n",
            "('and', 'possess'):0.00847457627118644\n",
            "('possess', 'phrase'):1.0\n",
            "('phrase', 'structure'):1.0\n",
            "('structure', 'with'):0.25\n",
            "('with', 'various'):0.047619047619047616\n",
            "('various', 'forms'):0.125\n",
            "('forms', 'of'):0.3333333333333333\n",
            "('of', 'punctuation'):0.005681818181818182\n",
            "('punctuation', '.'):1.0\n",
            "('.', 'Traditionally'):0.00684931506849315\n",
            "('Traditionally', ','):1.0\n",
            "(',', 'composers'):0.006578947368421052\n",
            "('composers', 'have'):1.0\n",
            "('have', 'employed'):0.08333333333333333\n",
            "('employed', 'pattern'):0.5\n",
            "('pattern', 'propagation'):1.0\n",
            "('propagation', 'intuitively'):0.5\n",
            "('intuitively', ','):0.5\n",
            "(',', 'but'):0.013157894736842105\n",
            "('but', 'algorithmic'):0.16666666666666666\n",
            "('algorithmic', 'composition'):1.0\n",
            "('composition', 'techniques'):0.5\n",
            "('techniques', 'allow'):0.07142857142857142\n",
            "('allow', 'the'):1.0\n",
            "('the', 'pattern'):0.005434782608695652\n",
            "('propagation', 'to'):0.5\n",
            "('be', 'formalized'):0.038461538461538464\n",
            "('formalized', ','):1.0\n",
            "(',', 'albeit'):0.006578947368421052\n",
            "('albeit', 'a'):1.0\n",
            "('a', 'high'):0.00980392156862745\n",
            "('level', '.'):0.5\n",
            "('.', 'During'):0.0136986301369863\n",
            "('During', 'composition'):0.5\n",
            "('composition', ','):0.5\n",
            "('all', 'the'):0.2857142857142857\n",
            "('the', 'musical'):0.005434782608695652\n",
            "('musical', 'patterns'):0.3333333333333333\n",
            "('patterns', 'evolve'):0.3333333333333333\n",
            "('evolve', 'according'):1.0\n",
            "('according', 'to'):1.0\n",
            "('the', 'rules'):0.005434782608695652\n",
            "('rules', 'and'):0.5\n",
            "('and', 'constraints'):0.00847457627118644\n",
            "('constraints', 'specied'):0.5\n",
            "('specied', 'at'):1.0\n",
            "('the', 'design'):0.016304347826086956\n",
            "('design', 'stage'):0.25\n",
            "('stage', '.'):1.0\n",
            "('In', 'jazz'):0.058823529411764705\n",
            "('jazz', 'improvisation'):1.0\n",
            "('improvisation', ','):1.0\n",
            "('the', 'musician'):0.005434782608695652\n",
            "('musician', 'invents'):1.0\n",
            "('invents', 'a'):1.0\n",
            "('a', 'solo'):0.00980392156862745\n",
            "('solo', 'guided'):0.5\n",
            "('guided', 'by'):1.0\n",
            "('by', 'a'):0.05555555555555555\n",
            "('a', 'progression'):0.00980392156862745\n",
            "('progression', 'of'):0.5\n",
            "('of', 'chords'):0.005681818181818182\n",
            "('chords', '('):1.0\n",
            "('(', 'the'):0.0196078431372549\n",
            "('the', 'changes'):0.005434782608695652\n",
            "('changes', ')'):1.0\n",
            "('.', 'One'):0.0136986301369863\n",
            "('One', 'approach'):0.5\n",
            "('approach', '['):0.09090909090909091\n",
            "('[', '1'):0.2\n",
            "('1', ']'):0.1111111111111111\n",
            "(']', 'to'):0.2\n",
            "('to', 'learn'):0.013513513513513514\n",
            "('learn', 'improvising'):0.5\n",
            "('improvising', 'is'):1.0\n",
            "('to', 'memorize'):0.013513513513513514\n",
            "('memorize', 'patterns'):1.0\n",
            "('patterns', '('):0.3333333333333333\n",
            "('(', 'short'):0.0196078431372549\n",
            "('short', 'chunks'):0.5\n",
            "('chunks', 'of'):0.5\n",
            "('music', ')'):0.25\n",
            "(')', 'that'):0.0425531914893617\n",
            "('that', 't'):0.02631578947368421\n",
            "('t', 'sub-progressions'):1.0\n",
            "('sub-progressions', ','):1.0\n",
            "('and', 'to'):0.00847457627118644\n",
            "('to', 'concatenate'):0.013513513513513514\n",
            "('concatenate', 'them'):1.0\n",
            "('them', 'to'):0.25\n",
            "('to', 'form'):0.013513513513513514\n",
            "('form', 'a'):0.5\n",
            "('a', 'whole'):0.0196078431372549\n",
            "('whole', 'solo'):0.5\n",
            "('solo', 'that'):0.5\n",
            "('that', 'ts'):0.02631578947368421\n",
            "('ts', 'a'):1.0\n",
            "('whole', 'progression'):0.5\n",
            "('progression', '.'):0.5\n",
            "('One', 'Abstract'):0.5\n",
            "('Abstract', 'Many'):0.07692307692307693\n",
            "('Many', 'information'):0.3333333333333333\n",
            "('retrieval', '('):0.1111111111111111\n",
            "('(', 'IR'):0.0196078431372549\n",
            "('IR', ')'):1.0\n",
            "(')', 'systems'):0.02127659574468085\n",
            "('systems', 'retrieve'):0.06666666666666667\n",
            "('retrieve', 'relevant'):1.0\n",
            "('relevant', 'documents'):0.6666666666666666\n",
            "('documents', 'based'):0.2\n",
            "('on', 'exact'):0.043478260869565216\n",
            "('exact', 'matching'):1.0\n",
            "('matching', 'of'):0.5\n",
            "('of', 'keywords'):0.005681818181818182\n",
            "('keywords', 'between'):1.0\n",
            "('between', 'a'):0.125\n",
            "('a', 'query'):0.00980392156862745\n",
            "('query', 'and'):0.3333333333333333\n",
            "('and', 'documents'):0.00847457627118644\n",
            "('documents', '.'):0.2\n",
            "('This', 'method'):0.034482758620689655\n",
            "('method', 'degrades'):0.2\n",
            "('degrades', 'precision'):1.0\n",
            "('precision', 'rate'):1.0\n",
            "('rate', '.'):0.5\n",
            "('In', 'order'):0.058823529411764705\n",
            "('solve', 'the'):0.5\n",
            "('the', 'problem'):0.005434782608695652\n",
            "('problem', ','):1.0\n",
            "('we', 'collected'):0.058823529411764705\n",
            "('collected', 'semantically'):1.0\n",
            "('semantically', 'related'):0.5\n",
            "('related', 'words'):0.5\n",
            "('words', 'and'):0.3333333333333333\n",
            "('and', 'assigned'):0.00847457627118644\n",
            "('assigned', 'semantic'):1.0\n",
            "('semantic', 'relationships'):0.125\n",
            "('relationships', 'used'):0.5\n",
            "('used', 'in'):0.45454545454545453\n",
            "('general', 'thesaurus'):0.3333333333333333\n",
            "('thesaurus', 'and'):0.5\n",
            "('and', 'a'):0.00847457627118644\n",
            "('a', 'special'):0.00980392156862745\n",
            "('special', 'relationship'):0.5\n",
            "('relationship', 'called'):1.0\n",
            "('called', 'keyfact'):0.5\n",
            "('keyfact', 'term'):0.5\n",
            "('term', '('):0.5\n",
            "('(', 'FT'):0.0196078431372549\n",
            "('FT', ')'):1.0\n",
            "(')', 'manually'):0.02127659574468085\n",
            "('manually', '.'):0.5\n",
            "('In', 'addition'):0.058823529411764705\n",
            "('addition', 'to'):1.0\n",
            "('semantic', 'knowledge'):0.125\n",
            "('knowledge', ','):0.08333333333333333\n",
            "('we', 'automatically'):0.058823529411764705\n",
            "('automatically', 'constructed'):0.3333333333333333\n",
            "('constructed', 'statistic'):1.0\n",
            "('statistic', 'knowledge'):1.0\n",
            "('knowledge', 'based'):0.08333333333333333\n",
            "('the', 'concept'):0.005434782608695652\n",
            "('concept', 'of'):1.0\n",
            "('of', 'mutual'):0.005681818181818182\n",
            "('mutual', 'information'):1.0\n",
            "('information', '.'):0.10526315789473684\n",
            "('.', 'Keyfact'):0.0136986301369863\n",
            "('Keyfact', 'is'):0.5\n",
            "('an', 'extended'):0.05\n",
            "('extended', 'concept'):1.0\n",
            "('of', 'keyword'):0.005681818181818182\n",
            "('keyword', 'represented'):1.0\n",
            "('represented', 'by'):1.0\n",
            "('by', 'noun'):0.05555555555555555\n",
            "('noun', 'and'):0.5\n",
            "('and', 'compound'):0.00847457627118644\n",
            "('compound', 'noun'):0.3333333333333333\n",
            "('noun', '.'):0.5\n",
            "('Keyfact', 'can'):0.5\n",
            "('be', 'a'):0.038461538461538464\n",
            "('a', 'verb'):0.00980392156862745\n",
            "('verb', 'and'):1.0\n",
            "('and', 'an'):0.00847457627118644\n",
            "('an', 'adjective'):0.05\n",
            "('adjective', 'including'):1.0\n",
            "('including', 'subject'):0.125\n",
            "('subject', 'or'):0.5\n",
            "('or', 'object'):0.058823529411764705\n",
            "('object', 'term'):0.5\n",
            "('term', '.'):0.5\n",
            "('We', 'first'):0.041666666666666664\n",
            "('first', 'retrieved'):0.3333333333333333\n",
            "('retrieved', 'relevant'):1.0\n",
            "('documents', 'with'):0.2\n",
            "('with', 'original'):0.047619047619047616\n",
            "('original', 'query'):1.0\n",
            "('query', 'using'):0.3333333333333333\n",
            "('using', 'tf'):0.09090909090909091\n",
            "('tf', '*'):1.0\n",
            "('*', 'idf'):1.0\n",
            "('idf', 'weighting'):1.0\n",
            "('weighting', 'formula'):0.5\n",
            "('formula', 'and'):1.0\n",
            "('and', 'then'):0.03389830508474576\n",
            "('then', 'an'):0.2\n",
            "('an', 'expanded'):0.05\n",
            "('expanded', 'query'):0.5\n",
            "('query', 'including'):0.3333333333333333\n",
            "('including', 'keyfacts'):0.125\n",
            "('keyfacts', 'is'):1.0\n",
            "('is', 'used'):0.018518518518518517\n",
            "('both', 'second'):0.2\n",
            "('second', 'document'):1.0\n",
            "('document', 'ranking'):0.2\n",
            "('ranking', 'and'):1.0\n",
            "('and', 'word'):0.00847457627118644\n",
            "('word', 'sense'):0.42857142857142855\n",
            "('sense', 'disambiguating'):0.2\n",
            "('disambiguating', '.'):1.0\n",
            "('So', 'we'):0.5\n",
            "('we', 'made'):0.058823529411764705\n",
            "('made', 'an'):0.3333333333333333\n",
            "('an', 'improvement'):0.05\n",
            "('improvement', 'in'):0.5\n",
            "('in', 'precision'):0.013333333333333334\n",
            "('rate', 'using'):0.5\n",
            "('using', 'keyfact'):0.09090909090909091\n",
            "('keyfact', 'network'):0.5\n",
            "('network', '.'):0.2\n",
            "('paper', 'we'):0.09523809523809523\n",
            "('we', 'argue'):0.058823529411764705\n",
            "('that', 'questionanswering'):0.02631578947368421\n",
            "('questionanswering', '('):1.0\n",
            "('(', 'QA'):0.0196078431372549\n",
            "('QA', ')'):0.3333333333333333\n",
            "(')', 'over'):0.02127659574468085\n",
            "('over', 'technical'):0.2\n",
            "('technical', 'domains'):1.0\n",
            "('domains', 'is'):0.3333333333333333\n",
            "('is', 'distinctly'):0.018518518518518517\n",
            "('distinctly', 'different'):1.0\n",
            "('different', 'from'):0.25\n",
            "('from', 'TREC-based'):0.05555555555555555\n",
            "('TREC-based', 'QA'):1.0\n",
            "('QA', 'or'):0.3333333333333333\n",
            "('or', 'Web-based'):0.058823529411764705\n",
            "('Web-based', 'QA'):0.5\n",
            "('QA', 'and'):0.3333333333333333\n",
            "('and', 'it'):0.00847457627118644\n",
            "('it', 'can'):0.1\n",
            "('can', 'not'):0.0625\n",
            "('not', 'benefit'):0.07142857142857142\n",
            "('benefit', 'lom'):0.5\n",
            "('lom', 'data-intensive'):1.0\n",
            "('data-intensive', 'approaches'):1.0\n",
            "('approaches', 'Universit'):0.16666666666666666\n",
            "('Universit', '&'):1.0\n",
            "('&', 'quot'):0.3333333333333333\n",
            "('quot', ';'):1.0\n",
            "(';', 'at'):0.16666666666666666\n",
            "('at', 'des'):0.14285714285714285\n",
            "('des', 'Saarlandes'):1.0\n",
            "('Saarlandes', 'Proceedings'):1.0\n",
            "('Proceedings', 'of'):1.0\n",
            "('the', 'Workshop'):0.005434782608695652\n",
            "('Workshop', 'on'):1.0\n",
            "('on', 'uni-hamburg.de'):0.043478260869565216\n",
            "('uni-hamburg.de', 'Abstract'):1.0\n",
            "('found', 'Abstract'):0.25\n",
            "('found', 'SRI'):0.125\n",
            "('SRI', 'has'):1.0\n",
            "('has', 'developed'):0.08333333333333333\n",
            "('developed', 'a'):0.4\n",
            "('new', 'architecture'):0.16666666666666666\n",
            "('architecture', 'for'):0.25\n",
            "('for', 'integrating'):0.017857142857142856\n",
            "('integrating', 'speech'):0.5\n",
            "('speech', 'and'):0.125\n",
            "('and', 'natural-language'):0.00847457627118644\n",
            "('natural-language', 'processing'):1.0\n",
            "('processing', 'that'):0.015625\n",
            "('that', 'applies'):0.02631578947368421\n",
            "('applies', 'linguistic'):1.0\n",
            "('linguistic', 'constraints'):0.14285714285714285\n",
            "('constraints', 'during'):0.5\n",
            "('during', 'recognition'):0.3333333333333333\n",
            "('recognition', 'by'):0.08333333333333333\n",
            "('by', 'incrementally'):0.05555555555555555\n",
            "('incrementally', 'expanding'):1.0\n",
            "('expanding', 'the'):1.0\n",
            "('the', 'state-transition'):0.005434782608695652\n",
            "('state-transition', 'network'):1.0\n",
            "('network', 'embodied'):0.2\n",
            "('embodied', 'in'):1.0\n",
            "('a', 'unification'):0.00980392156862745\n",
            "('unification', 'grammar'):1.0\n",
            "('grammar', '.'):0.5\n",
            "('We', 'compare'):0.041666666666666664\n",
            "('compare', 'this'):1.0\n",
            "('this', 'dynamic-gralnlnar-network'):0.045454545454545456\n",
            "('dynamic-gralnlnar-network', '('):1.0\n",
            "('(', 'DGN'):0.0196078431372549\n",
            "('DGN', ')'):1.0\n",
            "(')', 'approach'):0.02127659574468085\n",
            "('approach', 'This'):0.18181818181818182\n",
            "('This', 'chapter'):0.13793103448275862\n",
            "('chapter', 'considers'):0.25\n",
            "('considers', 'the'):1.0\n",
            "('the', 'revolution'):0.005434782608695652\n",
            "('revolution', 'that'):1.0\n",
            "('that', 'has'):0.02631578947368421\n",
            "('has', 'taken'):0.08333333333333333\n",
            "('taken', 'place'):0.5\n",
            "('place', 'in'):1.0\n",
            "('processing', 'research'):0.015625\n",
            "('research', 'over'):0.08333333333333333\n",
            "('over', 'the'):0.8\n",
            "('the', 'last'):0.021739130434782608\n",
            "('last', 'five'):0.25\n",
            "('five', 'years'):1.0\n",
            "('It', 'begins'):0.2\n",
            "('begins', 'by'):1.0\n",
            "('by', 'providing'):0.05555555555555555\n",
            "('providing', 'a'):1.0\n",
            "('a', 'brief'):0.0196078431372549\n",
            "('brief', 'guide'):0.3333333333333333\n",
            "('guide', 'to'):1.0\n",
            "('the', 'structure'):0.005434782608695652\n",
            "('structure', 'of'):0.25\n",
            "('the', 'field'):0.005434782608695652\n",
            "('field', 'and'):0.2\n",
            "('then', 'presents'):0.2\n",
            "('presents', 'a'):0.6666666666666666\n",
            "('a', 'caricature'):0.00980392156862745\n",
            "('caricature', 'of'):1.0\n",
            "('of', 'two'):0.005681818181818182\n",
            "('two', 'competing'):0.3333333333333333\n",
            "('competing', 'paradigms'):1.0\n",
            "('paradigms', 'of'):1.0\n",
            "('of', '1980s'):0.005681818181818182\n",
            "('1980s', 'NLP'):1.0\n",
            "('NLP', 'research'):0.022727272727272728\n",
            "('research', 'and'):0.16666666666666666\n",
            "('and', 'indicates'):0.00847457627118644\n",
            "('indicates', 'the'):1.0\n",
            "('the', 'reasons'):0.005434782608695652\n",
            "('reasons', 'visual'):1.0\n",
            "('visual', 'development'):0.3333333333333333\n",
            "('development', 'environment'):0.1111111111111111\n",
            "('environment', 'to'):0.5\n",
            "('to', 'support'):0.013513513513513514\n",
            "('support', 'the'):0.5\n",
            "('the', 'visual'):0.005434782608695652\n",
            "('visual', 'assembly'):0.3333333333333333\n",
            "('assembly', ','):1.0\n",
            "(',', 'execution'):0.006578947368421052\n",
            "('execution', 'and'):0.5\n",
            "('and', 'analysis'):0.00847457627118644\n",
            "('of', 'modular'):0.005681818181818182\n",
            "('modular', 'natural'):1.0\n",
            "('The', 'visual'):0.038461538461538464\n",
            "('visual', 'model'):0.3333333333333333\n",
            "('model', 'is'):0.14285714285714285\n",
            "('an', 'executable'):0.05\n",
            "('executable', 'data'):1.0\n",
            "('data', 'flow'):0.16666666666666666\n",
            "('flow', 'program'):1.0\n",
            "('program', 'graph'):0.3333333333333333\n",
            "('graph', ','):0.5\n",
            "(',', 'automatically'):0.006578947368421052\n",
            "('automatically', 'synthesised'):0.3333333333333333\n",
            "('synthesised', 'from'):1.0\n",
            "('from', 'data'):0.05555555555555555\n",
            "('data', 'dependency'):0.16666666666666666\n",
            "('dependency', 'declarations'):0.5\n",
            "('declarations', 'of'):1.0\n",
            "('processing', 'modules'):0.015625\n",
            "('modules', '.'):1.0\n",
            "('The', 'graph'):0.038461538461538464\n",
            "('graph', 'In'):0.5\n",
            "('this', 'Chapter'):0.045454545454545456\n",
            "('Chapter', 'the'):1.0\n",
            "('the', 'basic'):0.016304347826086956\n",
            "('basic', 'uses'):0.25\n",
            "('uses', 'of'):0.5\n",
            "('of', 'Description'):0.011363636363636364\n",
            "('Logics', 'for'):0.25\n",
            "('for', 'Natural'):0.017857142857142856\n",
            "('Processing', 'will'):0.05\n",
            "('will', 'be'):0.4444444444444444\n",
            "('be', 'analysed'):0.038461538461538464\n",
            "('analysed', ','):1.0\n",
            "(',', 'together'):0.006578947368421052\n",
            "('together', 'with'):1.0\n",
            "('a', 'little'):0.00980392156862745\n",
            "('little', 'bit'):1.0\n",
            "('bit', 'of'):1.0\n",
            "('of', 'history'):0.011363636363636364\n",
            "('history', ','):0.25\n",
            "('Logics', 'in'):0.25\n",
            "('state', 'of'):0.6\n",
            "('the', 'art'):0.016304347826086956\n",
            "('art', 'in'):0.25\n",
            "('linguistics', 'will'):0.2\n",
            "('be', 'pointed'):0.038461538461538464\n",
            "('pointed', 'out'):1.0\n",
            "('out', '.'):0.3333333333333333\n",
            "('.', '18.1'):0.00684931506849315\n",
            "('18.1', 'Introduction'):1.0\n",
            "('Introduction', 'Since'):0.2\n",
            "('Since', 'the'):1.0\n",
            "('the', 'early'):0.005434782608695652\n",
            "('early', 'days'):1.0\n",
            "('days', 'We'):1.0\n",
            "('We', 'applied'):0.041666666666666664\n",
            "('applied', 'a'):0.25\n",
            "('a', 'structure'):0.00980392156862745\n",
            "('structure', 'learning'):0.25\n",
            "('learning', 'model'):0.05\n",
            "('model', ','):0.14285714285714285\n",
            "(',', 'Max-Margin'):0.006578947368421052\n",
            "('Max-Margin', 'Structure'):1.0\n",
            "('Structure', '('):1.0\n",
            "('(', 'MMS'):0.0196078431372549\n",
            "('MMS', ')'):1.0\n",
            "(')', 'tasks'):0.06382978723404255\n",
            "(',', 'where'):0.006578947368421052\n",
            "('where', 'the'):0.5\n",
            "('the', 'aim'):0.005434782608695652\n",
            "('aim', 'is'):1.0\n",
            "('capture', 'the'):0.6666666666666666\n",
            "('the', 'latent'):0.005434782608695652\n",
            "('latent', 'relationships'):1.0\n",
            "('relationships', 'within'):0.5\n",
            "('within', 'the'):0.2\n",
            "('the', 'output'):0.005434782608695652\n",
            "('output', 'language'):0.5\n",
            "('language', 'domain'):0.011764705882352941\n",
            "('domain', '.'):0.5\n",
            "('We', 'formulate'):0.041666666666666664\n",
            "('formulate', 'this'):1.0\n",
            "('this', 'model'):0.045454545454545456\n",
            "('model', 'as'):0.14285714285714285\n",
            "('as', 'an'):0.13333333333333333\n",
            "('an', 'extension'):0.05\n",
            "('extension', 'of'):1.0\n",
            "('of', 'multiâ€“class'):0.005681818181818182\n",
            "('multiâ€“class', 'Support'):1.0\n",
            "('Support', 'Vector'):1.0\n",
            "('Vector', 'Machine'):1.0\n",
            "('Machine', '('):0.3333333333333333\n",
            "('(', 'SVM'):0.0196078431372549\n",
            "('SVM', ')'):1.0\n",
            "('and', 'present'):0.00847457627118644\n",
            "('a', '-mation'):0.00980392156862745\n",
            "('-mation', 'Infrastructure'):1.0\n",
            "('Infrastructure', ','):1.0\n",
            "(',', 'digital'):0.013157894736842105\n",
            "('digital', 'libraries'):0.3333333333333333\n",
            "('libraries', ','):1.0\n",
            "(',', 'networked'):0.006578947368421052\n",
            "('networked', 'services'):1.0\n",
            "('services', ','):1.0\n",
            "('digital', 'convergence'):0.3333333333333333\n",
            "('convergence', 'or'):1.0\n",
            "('or', 'intelligent'):0.058823529411764705\n",
            "('intelligent', 'agents'):0.5\n",
            "('agents', '.'):1.0\n",
            "('This', 'attention'):0.034482758620689655\n",
            "('attention', 'is'):1.0\n",
            "('is', 'moving'):0.018518518518518517\n",
            "('moving', 'natural'):1.0\n",
            "('processing', 'along'):0.015625\n",
            "('along', 'the'):1.0\n",
            "('the', 'critical'):0.005434782608695652\n",
            "('critical', 'path'):1.0\n",
            "('path', 'for'):1.0\n",
            "('for', 'all'):0.017857142857142856\n",
            "('all', 'kinds'):0.14285714285714285\n",
            "('of', 'novel'):0.005681818181818182\n",
            "('novel', 'applications'):1.0\n",
            "('applications', '.'):0.36363636363636365\n",
            "('article', 'will'):0.3333333333333333\n",
            "('will', 'mention'):0.1111111111111111\n",
            "('mention', 'a'):1.0\n",
            "('of', 'successful'):0.005681818181818182\n",
            "('successful', 'applications'):1.0\n",
            "('NLP', 'Over'):0.022727272727272728\n",
            "('Over', 'the'):1.0\n",
            "('last', 'few'):0.25\n",
            "('few', 'years'):1.0\n",
            "(',', 'a'):0.03289473684210526\n",
            "('of', 'areas'):0.005681818181818182\n",
            "('areas', 'of'):1.0\n",
            "('processing', 'have'):0.015625\n",
            "('have', 'begun'):0.08333333333333333\n",
            "('begun', 'applying'):1.0\n",
            "('applying', 'graph-based'):0.5\n",
            "('graph-based', 'techniques'):1.0\n",
            "('.', 'These'):0.00684931506849315\n",
            "('These', 'include'):1.0\n",
            "('include', ','):0.5\n",
            "(',', 'among'):0.006578947368421052\n",
            "('among', 'others'):0.3333333333333333\n",
            "('others', ','):1.0\n",
            "('text', 'summarization'):0.1\n",
            "('summarization', ','):1.0\n",
            "('syntactic', 'parsing'):0.3333333333333333\n",
            "('parsing', ','):0.5\n",
            "(',', 'word'):0.013157894736842105\n",
            "('sense', 'disambiguation'):0.4\n",
            "('disambiguation', ','):0.5\n",
            "(',', 'ontology'):0.006578947368421052\n",
            "('ontology', 'construction'):1.0\n",
            "('construction', ','):1.0\n",
            "(',', 'sentiment'):0.006578947368421052\n",
            "('sentiment', 'and'):1.0\n",
            "('and', 'subjectivity'):0.00847457627118644\n",
            "('subjectivity', 'analysis'):1.0\n",
            "('text', 'clustering'):0.1\n",
            "('clustering', 'In'):1.0\n",
            "('In', 'Natural'):0.058823529411764705\n",
            "(',', 'research'):0.006578947368421052\n",
            "('research', 'results'):0.25\n",
            "('results', 'from'):0.14285714285714285\n",
            "('from', 'software'):0.05555555555555555\n",
            "('software', 'engineering'):0.25\n",
            "('engineering', 'and'):0.5\n",
            "('and', 'software'):0.01694915254237288\n",
            "('software', 'technology'):0.25\n",
            "('technology', 'have'):0.3333333333333333\n",
            "('have', 'often'):0.08333333333333333\n",
            "('often', 'been'):0.5\n",
            "('been', 'neglected'):0.07692307692307693\n",
            "('neglected', '.'):1.0\n",
            "('.', 'of'):0.00684931506849315\n",
            "('of', 'kernelized'):0.011363636363636364\n",
            "('kernelized', 'sorting'):0.5\n",
            "('sorting', 'to'):1.0\n",
            "('to', 'increase'):0.013513513513513514\n",
            "('increase', 'its'):1.0\n",
            "('its', 'robustness'):0.3333333333333333\n",
            "('robustness', 'and'):1.0\n",
            "('and', 'performance'):0.00847457627118644\n",
            "('performance', 'on'):0.25\n",
            "('on', 'several'):0.043478260869565216\n",
            "('several', 'Natural'):0.25\n",
            "('tasks', ':'):0.0625\n",
            "(':', 'document'):0.05263157894736842\n",
            "('document', 'matching'):0.2\n",
            "('matching', 'from'):0.5\n",
            "('from', 'parallel'):0.05555555555555555\n",
            "('parallel', 'and'):0.5\n",
            "('and', 'comparable'):0.00847457627118644\n",
            "('comparable', 'corpora'):1.0\n",
            "('corpora', ','):1.0\n",
            "('machine', 'transliteration'):0.07142857142857142\n",
            "('transliteration', 'and'):1.0\n",
            "('and', 'even'):0.00847457627118644\n",
            "('even', 'image'):0.5\n",
            "('image', 'processing'):1.0\n",
            "('.', 'Empirically'):0.00684931506849315\n",
            "('Empirically', 'we'):1.0\n",
            "('we', 'show'):0.058823529411764705\n",
            "('show', 'that'):1.0\n",
            "('that', ','):0.05263157894736842\n",
            "(',', 'on'):0.006578947368421052\n",
            "('on', 'these'):0.043478260869565216\n",
            "('these', 'tasks'):0.2\n",
            "('a', 'semi-supervised'):0.00980392156862745\n",
            "('semi-supervised', 'variant'):1.0\n",
            "('variant', 'of'):1.0\n",
            "('kernelized', 'will'):0.5\n",
            "('be', 'structured'):0.038461538461538464\n",
            "('structured', '.'):0.5\n",
            "('the', 'words'):0.005434782608695652\n",
            "('words', 'of'):0.16666666666666666\n",
            "('of', 'statistical'):0.005681818181818182\n",
            "('statistical', 'natural'):0.14285714285714285\n",
            "('processing', ','):0.0625\n",
            "('we', 'need'):0.058823529411764705\n",
            "('need', 'a'):0.16666666666666666\n",
            "('a', 'sophisticated'):0.00980392156862745\n",
            "('sophisticated', 'statistical'):0.5\n",
            "('statistical', 'model'):0.14285714285714285\n",
            "('basic', 'elements'):0.25\n",
            "('elements', ','):0.3333333333333333\n",
            "('as', 'words'):0.06666666666666667\n",
            "('words', 'or'):0.16666666666666666\n",
            "('or', 'phrases'):0.058823529411764705\n",
            "('phrases', ','):1.0\n",
            "('be', 'combined'):0.038461538461538464\n",
            "('combined', 'with'):1.0\n",
            "('the', 'structural'):0.005434782608695652\n",
            "('structural', 'modeling'):1.0\n",
            "('modeling', 'such'):0.3333333333333333\n",
            "('as', 'syntactic'):0.06666666666666667\n",
            "('parsing', 'or'):0.25\n",
            "('or', 'dependency'):0.058823529411764705\n",
            "('dependency', 'analysis'):0.5\n",
            "('analysis', '.'):0.18181818181818182\n",
            "('.', 'Since'):0.00684931506849315\n",
            "('basic', 'property'):0.25\n",
            "('property', 'of'):1.0\n",
            "('of', 'these'):0.005681818181818182\n",
            "('these', 'elements'):0.2\n",
            "('elements', 'In'):0.3333333333333333\n",
            "('a', 'framework'):0.00980392156862745\n",
            "('framework', 'for'):0.5\n",
            "('for', 'developing'):0.017857142857142856\n",
            "('developing', 'probabilistic'):1.0\n",
            "('probabilistic', 'classifiers'):0.5\n",
            "('classifiers', 'in'):1.0\n",
            "('Our', 'focus'):0.5\n",
            "('focus', 'is'):0.16666666666666666\n",
            "('is', 'on'):0.018518518518518517\n",
            "('on', 'formulating'):0.043478260869565216\n",
            "('formulating', 'models'):1.0\n",
            "('models', 'that'):0.25\n",
            "('that', 'capture'):0.02631578947368421\n",
            "('the', 'most'):0.005434782608695652\n",
            "('most', 'important'):0.5\n",
            "('important', 'interdependencies'):0.3333333333333333\n",
            "('interdependencies', 'among'):1.0\n",
            "('among', 'features'):0.3333333333333333\n",
            "('features', ','):0.5\n",
            "('avoid', 'overfitting'):0.3333333333333333\n",
            "('overfitting', 'the'):1.0\n",
            "('the', 'data'):0.010869565217391304\n",
            "('data', 'while'):0.16666666666666666\n",
            "('while', 'also'):0.3333333333333333\n",
            "('also', 'characterizing'):0.2\n",
            "('characterizing', 'the'):1.0\n",
            "('data', 'well'):0.16666666666666666\n",
            "('well', '.'):1.0\n",
            "('The', 'class'):0.038461538461538464\n",
            "('class', 'Many'):0.5\n",
            "('Many', 'Natural'):0.3333333333333333\n",
            "('techniques', 'have'):0.07142857142857142\n",
            "('in', 'Information'):0.013333333333333334\n",
            "('Information', 'Retrieval'):0.3333333333333333\n",
            "('Retrieval', '.'):1.0\n",
            "('The', 'results'):0.038461538461538464\n",
            "('results', 'are'):0.14285714285714285\n",
            "('not', 'encouraging'):0.07142857142857142\n",
            "('encouraging', '.'):1.0\n",
            "('.', 'Simple'):0.00684931506849315\n",
            "('Simple', 'methods'):1.0\n",
            "('methods', '('):0.3333333333333333\n",
            "('(', 'stopwording'):0.0196078431372549\n",
            "('stopwording', ','):1.0\n",
            "(',', 'porter-style'):0.006578947368421052\n",
            "('porter-style', 'stemming'):1.0\n",
            "('stemming', ','):1.0\n",
            "(',', 'etc'):0.006578947368421052\n",
            "('etc', '.'):1.0\n",
            "('.', ')'):0.00684931506849315\n",
            "(')', 'usually'):0.02127659574468085\n",
            "('usually', 'yield'):1.0\n",
            "('yield', 'significant'):1.0\n",
            "('significant', 'improvements'):0.3333333333333333\n",
            "('improvements', ','):1.0\n",
            "(',', 'while'):0.006578947368421052\n",
            "('while', 'higher-level'):0.3333333333333333\n",
            "('higher-level', 'processing'):1.0\n",
            "('(', 'chunking'):0.0196078431372549\n",
            "(',', 'parsing'):0.006578947368421052\n",
            "('disambiguation', 'Abstract-'):0.5\n",
            "('Abstract-', 'This'):1.0\n",
            "('paper', 'explains'):0.047619047619047616\n",
            "('explains', 'the'):1.0\n",
            "('the', 'information'):0.021739130434782608\n",
            "('retrieval', 'using'):0.1111111111111111\n",
            "('for', 'Malayalam'):0.017857142857142856\n",
            "('Malayalam', 'language'):1.0\n",
            "('in', 'these'):0.013333333333333334\n",
            "('these', 'basic'):0.2\n",
            "('basic', 'in'):0.25\n",
            "('the', 'state'):0.016304347826086956\n",
            "('art', 'plan'):0.5\n",
            "('plan', 'recognition'):1.0\n",
            "('recognition', 'systems'):0.16666666666666666\n",
            "('paper', 'will'):0.09523809523809523\n",
            "('will', 'outline'):0.2222222222222222\n",
            "('outline', 'the'):1.0\n",
            "('the', 'relations'):0.010869565217391304\n",
            "('relations', 'between'):1.0\n",
            "('between', 'natural'):0.25\n",
            "('and', 'plan'):0.01694915254237288\n",
            "('recognition', '('):0.16666666666666666\n",
            "('(', 'PR'):0.0392156862745098\n",
            "('PR', ')'):0.5\n",
            "(',', 'argue'):0.013157894736842105\n",
            "('that', 'each'):0.05263157894736842\n",
            "('each', 'of'):1.0\n",
            "('of', 'them'):0.011363636363636364\n",
            "('them', 'can'):0.5\n",
            "('can', 'effectively'):0.125\n",
            "('effectively', 'inform'):0.6666666666666666\n",
            "('inform', 'the'):1.0\n",
            "('the', 'other'):0.010869565217391304\n",
            "('other', ','):1.0\n",
            "('then', 'focus'):0.4\n",
            "('on', 'key'):0.08695652173913043\n",
            "('key', 'recent'):1.0\n",
            "('results', 'in'):0.2857142857142857\n",
            "('in', 'NLP'):0.02666666666666667\n",
            "('NLP', 'and'):0.045454545454545456\n",
            "('and', 'argue'):0.01694915254237288\n",
            "('argue', 'for'):0.3333333333333333\n",
            "('for', 'their'):0.03571428571428571\n",
            "('their', 'applicability'):0.5\n",
            "('applicability', 'to'):1.0\n",
            "('to', 'PR'):0.02702702702702703\n",
            "('PR', '.'):0.5\n",
            "('1', 'in'):0.1111111111111111\n",
            "('1', 'Information'):0.1111111111111111\n",
            "('Information', 'retrieval'):0.3333333333333333\n",
            "('retrieval', 'is'):0.1111111111111111\n",
            "('the', 'process'):0.010869565217391304\n",
            "('of', 'finding'):0.005681818181818182\n",
            "('finding', 'the'):1.0\n",
            "('the', 'documents'):0.005434782608695652\n",
            "('documents', 'in'):0.2\n",
            "('a', 'document'):0.00980392156862745\n",
            "('document', 'collection'):0.2\n",
            "('collection', 'that'):0.5\n",
            "('that', 'satisfies'):0.02631578947368421\n",
            "('satisfies', 'the'):1.0\n",
            "('information', 'need'):0.05263157894736842\n",
            "('need', 'of'):0.16666666666666666\n",
            "('the', 'user'):0.005434782608695652\n",
            "('user', '.'):1.0\n",
            "('The', 'documents'):0.038461538461538464\n",
            "('documents', 'are'):0.2\n",
            "('are', 'natural'):0.038461538461538464\n",
            "('language', 'constructs'):0.011764705882352941\n",
            "('constructs', ','):1.0\n",
            "('the', 'motivation'):0.005434782608695652\n",
            "('motivation', 'of'):1.0\n",
            "('this', 'work'):0.045454545454545456\n",
            "('work', 'is'):0.14285714285714285\n",
            "('to', 'investigate'):0.013513513513513514\n",
            "('investigate', 'how'):1.0\n",
            "('how', 'natural'):0.2\n",
            "('processing', 'can'):0.015625\n",
            "('be', 'used'):0.11538461538461539\n",
            "('improve', 'of'):0.5\n",
            "('of', 'logic'):0.005681818181818182\n",
            "('logic', 'programming'):0.8\n",
            "('programming', 'within'):0.2\n",
            "('within', 'both'):0.2\n",
            "('both', 'natural'):0.2\n",
            "('language', 'research'):0.011764705882352941\n",
            "('we', 'point'):0.058823529411764705\n",
            "('out', 'opportunities'):0.3333333333333333\n",
            "('opportunities', 'for'):0.3333333333333333\n",
            "('for', 'induction'):0.017857142857142856\n",
            "('induction', 'of'):1.0\n",
            "('knowledge', 'within'):0.08333333333333333\n",
            "('within', 'logic'):0.2\n",
            "('logic', '('):0.2\n",
            "('(', 'programming'):0.0196078431372549\n",
            "('programming', ')'):0.2\n",
            "('.', 'Keywords'):0.00684931506849315\n",
            "('Keywords', ':'):1.0\n",
            "(':', 'inductive'):0.05263157894736842\n",
            "('inductive', 'logic'):1.0\n",
            "('programming', ','):0.4\n",
            "(',', 'natural'):0.006578947368421052\n",
            "(',', 'logic'):0.006578947368421052\n",
            "('1', 'Introduction'):0.1111111111111111\n",
            "('Introduction', 'There'):0.2\n",
            "('There', 'is'):1.0\n",
            "('a', 'What'):0.00980392156862745\n",
            "('What', 'is'):1.0\n",
            "('a', 'statistical'):0.0196078431372549\n",
            "('statistical', 'method'):0.14285714285714285\n",
            "('method', 'and'):0.2\n",
            "('and', 'how'):0.00847457627118644\n",
            "('how', 'can'):0.2\n",
            "('can', 'it'):0.0625\n",
            "('it', 'be'):0.1\n",
            "(')', '?'):0.02127659574468085\n",
            "('?', 'In'):0.2\n",
            "('we', 'start'):0.058823529411764705\n",
            "('start', 'from'):1.0\n",
            "('a', 'definition'):0.00980392156862745\n",
            "('definition', 'of'):1.0\n",
            "('NLP', 'as'):0.022727272727272728\n",
            "('as', 'concerned'):0.06666666666666667\n",
            "('design', 'and'):0.5\n",
            "('and', 'implementation'):0.00847457627118644\n",
            "('implementation', 'of'):0.5\n",
            "('of', 'effective'):0.005681818181818182\n",
            "('effective', 'natural'):0.25\n",
            "('language', 'input'):0.011764705882352941\n",
            "('input', 'and'):1.0\n",
            "('and', 'output'):0.00847457627118644\n",
            "('output', 'components'):0.5\n",
            "('components', 'for'):0.5\n",
            "('for', 'computational'):0.017857142857142856\n",
            "('computational', 'systems'):0.2\n",
            "('We', 'distinguish'):0.041666666666666664\n",
            "('distinguish', 'three'):1.0\n",
            "('three', 'In'):0.3333333333333333\n",
            "('this', 'report'):0.045454545454545456\n",
            "('report', ','):0.5\n",
            "(',', 'some'):0.013157894736842105\n",
            "('some', 'collaborative'):0.2\n",
            "('collaborative', 'work'):1.0\n",
            "('work', 'between'):0.14285714285714285\n",
            "('between', 'the'):0.125\n",
            "('the', 'fields'):0.005434782608695652\n",
            "('fields', 'of'):0.3333333333333333\n",
            "('of', 'Machine'):0.005681818181818182\n",
            "('Machine', 'Learning'):0.3333333333333333\n",
            "('Learning', '('):1.0\n",
            "('is', 'presented'):0.018518518518518517\n",
            "('presented', '.'):0.5\n",
            "('The', 'document'):0.038461538461538464\n",
            "('document', 'is'):0.2\n",
            "('is', 'structured'):0.018518518518518517\n",
            "('structured', 'in'):0.5\n",
            "('in', 'two'):0.02666666666666667\n",
            "('two', 'parts'):0.3333333333333333\n",
            "('parts', '.'):1.0\n",
            "('The', 'first'):0.038461538461538464\n",
            "('first', 'part'):0.3333333333333333\n",
            "('part', 'includes'):0.3333333333333333\n",
            "('includes', 'a'):0.6666666666666666\n",
            "('a', 'superficial'):0.00980392156862745\n",
            "('superficial', 'but'):1.0\n",
            "('but', 'comprehensive'):0.16666666666666666\n",
            "('comprehensive', 'survey'):1.0\n",
            "('survey', 'covering'):1.0\n",
            "('covering', 'the'):0.5\n",
            "('state', '--'):0.2\n",
            "('--', 'of'):0.07142857142857142\n",
            "('of', '--'):0.005681818181818182\n",
            "('--', 'the'):0.07142857142857142\n",
            "('the', '--'):0.005434782608695652\n",
            "('--', 'art'):0.07142857142857142\n",
            "('art', 'of'):0.25\n",
            "('of', 'machine'):0.011363636363636364\n",
            "('learning', 'Abstract'):0.05\n",
            "('Abstract', '.'):0.07692307692307693\n",
            "('This', 'thesis'):0.034482758620689655\n",
            "('thesis', 'examines'):0.5\n",
            "('examines', 'the'):1.0\n",
            "('techniques', 'in'):0.07142857142857142\n",
            "('in', 'various'):0.02666666666666667\n",
            "('various', 'tasks'):0.125\n",
            "('tasks', 'of'):0.0625\n",
            "(',', 'mainly'):0.006578947368421052\n",
            "('mainly', 'for'):1.0\n",
            "('the', 'task'):0.005434782608695652\n",
            "('task', 'of'):0.25\n",
            "('of', 'information'):0.017045454545454544\n",
            "('information', 'extraction'):0.10526315789473684\n",
            "('extraction', 'from'):0.3333333333333333\n",
            "('from', 'texts'):0.05555555555555555\n",
            "('texts', '.'):0.5\n",
            "('The', 'objectives'):0.038461538461538464\n",
            "('objectives', 'are'):1.0\n",
            "('the', 'improvement'):0.010869565217391304\n",
            "('improvement', 'of'):0.5\n",
            "('of', 'adaptability'):0.005681818181818182\n",
            "('adaptability', 'of'):1.0\n",
            "('extraction', 'systems'):0.3333333333333333\n",
            "('systems', 'to'):0.13333333333333333\n",
            "('to', 'new'):0.013513513513513514\n",
            "('new', 'thematic'):0.16666666666666666\n",
            "('thematic', 'do-mains'):1.0\n",
            "('do-mains', '('):1.0\n",
            "('(', 'or'):0.0196078431372549\n",
            "('or', 'even'):0.058823529411764705\n",
            "('even', 'This'):0.5\n",
            "('chapter', 'examines'):0.5\n",
            "('to', 'computerassisted'):0.02702702702702703\n",
            "('computerassisted', 'language'):1.0\n",
            "('language', 'learning'):0.023529411764705882\n",
            "('learning', 'including'):0.1\n",
            "('including', 'the'):0.25\n",
            "('the', 'history'):0.010869565217391304\n",
            "('history', 'of'):0.5\n",
            "('of', 'work'):0.011363636363636364\n",
            "('work', 'in'):0.2857142857142857\n",
            "('in', 'this'):0.02666666666666667\n",
            "('this', 'field'):0.09090909090909091\n",
            "('field', 'over'):0.4\n",
            "('last', 'thirtyfive'):0.5\n",
            "('thirtyfive', 'years'):1.0\n",
            "('years', 'but'):0.25\n",
            "('but', 'with'):0.3333333333333333\n",
            "('on', 'current'):0.08695652173913043\n",
            "('current', 'developments'):0.2857142857142857\n",
            "('developments', 'and'):1.0\n",
            "('and', 'opportunities'):0.01694915254237288\n",
            "('opportunities', '.'):0.6666666666666666\n",
            "('.', '36.1'):0.00684931506849315\n",
            "('36.1', 'Traditional'):1.0\n",
            "('Traditional', 'approaches'):1.0\n",
            "('approaches', 'tointerpretation'):0.16666666666666666\n",
            "('tointerpretation', 'in'):1.0\n",
            "('processing', 'typically'):0.015625\n",
            "('typically', 'fall'):0.5\n",
            "('fall', 'into'):1.0\n",
            "('into', 'one'):0.16666666666666666\n",
            "('one', 'of'):0.2\n",
            "('of', 'three'):0.005681818181818182\n",
            "('three', 'classes'):0.3333333333333333\n",
            "('classes', ':'):0.3333333333333333\n",
            "(':', 'syntax-driven'):0.05263157894736842\n",
            "('syntax-driven', ','):1.0\n",
            "(',', 'semantics-driven'):0.006578947368421052\n",
            "('semantics-driven', ','):1.0\n",
            "('or', 'frame/task'):0.058823529411764705\n",
            "('frame/task', 'based'):1.0\n",
            "('based', '.'):0.125\n",
            "('.', 'Syntax-driven'):0.00684931506849315\n",
            "('Syntax-driven', 'approaches'):1.0\n",
            "('approaches', 'use'):0.16666666666666666\n",
            "('use', 'a'):0.08333333333333333\n",
            "('a', 'domain-independent'):0.00980392156862745\n",
            "('domain-independent', 'grammar'):1.0\n",
            "('grammar', 'to'):0.5\n",
            "('the', 'interpretation'):0.005434782608695652\n",
            "('interpretation', 'process'):0.3333333333333333\n",
            "('process', 'and'):0.125\n",
            "('and', 'produce'):0.00847457627118644\n",
            "('produce', 'a'):1.0\n",
            "('a', 'global'):0.0196078431372549\n",
            "('global', 'parse'):0.5\n",
            "('parse', 'Natural'):1.0\n",
            "('a', 'very'):0.00980392156862745\n",
            "('very', 'large'):0.5\n",
            "('large', 'and'):0.5\n",
            "('and', 'diverse'):0.00847457627118644\n",
            "('diverse', 'subtopic'):1.0\n",
            "('subtopic', 'of'):1.0\n",
            "('of', 'artificial'):0.011363636363636364\n",
            "('artificial', 'intelligence'):1.0\n",
            "('intelligence', '.'):0.5\n",
            "('.', 'As'):0.00684931506849315\n",
            "('As', 'a'):1.0\n",
            "('a', 'result'):0.00980392156862745\n",
            "('result', ','):1.0\n",
            "(',', 'NLP'):0.006578947368421052\n",
            "('NLP', 'itself'):0.022727272727272728\n",
            "('itself', 'has'):1.0\n",
            "('has', 'many'):0.08333333333333333\n",
            "('many', 'subtopics'):0.5\n",
            "('subtopics', 'including'):1.0\n",
            "('including', 'optical'):0.125\n",
            "('optical', 'character'):1.0\n",
            "('character', 'recognition'):1.0\n",
            "('text', 'to'):0.1\n",
            "('to', 'speech'):0.013513513513513514\n",
            "('speech', 'translators'):0.125\n",
            "('translators', ','):1.0\n",
            "(',', 'foreign'):0.006578947368421052\n",
            "('foreign', 'language'):1.0\n",
            "('language', 'reading'):0.011764705882352941\n",
            "('reading', 'and'):1.0\n",
            "('and', 'writing'):0.00847457627118644\n",
            "('writing', 'aids'):1.0\n",
            "('aids', ','):1.0\n",
            "('and', 'speech'):0.00847457627118644\n",
            "('recognition', 'Probabilistic'):0.08333333333333333\n",
            "('Probabilistic', 'finite-state'):1.0\n",
            "('finite-state', 'string'):1.0\n",
            "('string', 'transducers'):1.0\n",
            "('transducers', '('):1.0\n",
            "('(', 'FSTs'):0.0196078431372549\n",
            "('FSTs', ')'):0.5\n",
            "(')', 'are'):0.0425531914893617\n",
            "('are', 'extremely'):0.038461538461538464\n",
            "('extremely', 'popular'):1.0\n",
            "('popular', 'in'):1.0\n",
            "(',', 'due'):0.006578947368421052\n",
            "('due', 'to'):1.0\n",
            "('to', 'powerful'):0.013513513513513514\n",
            "('powerful', 'generic'):0.5\n",
            "('generic', 'methods'):0.3333333333333333\n",
            "('methods', 'for'):0.3333333333333333\n",
            "('for', 'applying'):0.017857142857142856\n",
            "('applying', ','):0.5\n",
            "(',', 'composing'):0.006578947368421052\n",
            "('composing', ','):1.0\n",
            "('learning', 'them'):0.05\n",
            "('them', '.'):0.25\n",
            "('.', 'Unfortunately'):0.00684931506849315\n",
            "('Unfortunately', ','):1.0\n",
            "(',', 'FSTs'):0.006578947368421052\n",
            "('FSTs', 'are'):0.5\n",
            "('not', 'a'):0.07142857142857142\n",
            "('a', 'good'):0.00980392156862745\n",
            "('good', 'fit'):0.5\n",
            "('fit', 'for'):1.0\n",
            "('for', 'much'):0.017857142857142856\n",
            "('much', 'of'):0.5\n",
            "('current', 'work'):0.14285714285714285\n",
            "('work', 'on'):0.14285714285714285\n",
            "('on', 'probabilistic'):0.043478260869565216\n",
            "('probabilistic', 'modeling'):0.5\n",
            "('modeling', 'for'):0.3333333333333333\n",
            "('for', 'machine'):0.017857142857142856\n",
            "('machine', 'ABSTRACT'):0.07142857142857142\n",
            "('ABSTRACT', '.'):0.25\n",
            "('this', 'special'):0.045454545454545456\n",
            "('special', 'issue'):0.5\n",
            "('of', 'TAL'):0.005681818181818182\n",
            "('TAL', ','):1.0\n",
            "('we', 'look'):0.058823529411764705\n",
            "('look', 'at'):1.0\n",
            "('the', 'fundamental'):0.005434782608695652\n",
            "('fundamental', 'principles'):0.5\n",
            "('principles', 'underlying'):0.5\n",
            "('underlying', 'evaluation'):1.0\n",
            "('We', 'adopt'):0.041666666666666664\n",
            "('adopt', 'a'):1.0\n",
            "('global', 'point'):0.5\n",
            "('point', 'of'):0.25\n",
            "('of', 'view'):0.005681818181818182\n",
            "('view', 'that'):1.0\n",
            "('that', 'goes'):0.02631578947368421\n",
            "('goes', 'beyond'):1.0\n",
            "('beyond', 'the'):1.0\n",
            "('the', 'horizon'):0.005434782608695652\n",
            "('horizon', 'of'):1.0\n",
            "('a', 'single'):0.029411764705882353\n",
            "('single', 'evaluation'):0.3333333333333333\n",
            "('evaluation', 'campaign'):0.125\n",
            "('campaign', 'or'):1.0\n",
            "('or', 'a'):0.058823529411764705\n",
            "('a', 'particular'):0.00980392156862745\n",
            "('particular', 'protocol'):0.2\n",
            "('protocol', '.'):1.0\n",
            "('.', 'After'):0.00684931506849315\n",
            "('After', 'a'):0.5\n",
            "('brief', 'review'):0.3333333333333333\n",
            "('review', 'of'):0.5\n",
            "('history', 'and'):0.25\n",
            "('and', 'terminology'):0.00847457627118644\n",
            "('terminology', 'Abstract'):1.0\n",
            "('found', 'Natural'):0.125\n",
            "('systems', '('):0.06666666666666667\n",
            "('that', 'extract'):0.02631578947368421\n",
            "('extract', 'clinical'):0.25\n",
            "('clinical', 'information'):1.0\n",
            "('from', 'textual'):0.05555555555555555\n",
            "('textual', 'reports'):1.0\n",
            "('reports', 'were'):1.0\n",
            "('were', 'shown'):1.0\n",
            "('shown', 'to'):0.5\n",
            "('be', 'effective'):0.038461538461538464\n",
            "('effective', 'for'):0.25\n",
            "('for', 'limited'):0.017857142857142856\n",
            "('limited', 'domains'):0.25\n",
            "('domains', 'and'):0.6666666666666666\n",
            "('for', 'particular'):0.017857142857142856\n",
            "('particular', 'applications'):0.2\n",
            "('.', 'Because'):0.00684931506849315\n",
            "('Because', 'an'):1.0\n",
            "('an', 'NLP'):0.05\n",
            "('NLP', 'system'):0.022727272727272728\n",
            "('system', 'typically'):0.07692307692307693\n",
            "('typically', 'requires'):0.5\n",
            "('requires', 'substantial'):1.0\n",
            "('substantial', 'resources'):1.0\n",
            "('resources', 'to'):0.2\n",
            "('to', 'develop'):0.013513513513513514\n",
            "('develop', ','):1.0\n",
            "('it', 'is'):0.2\n",
            "('is', 'beneficial'):0.018518518518518517\n",
            "('beneficial', 'if'):1.0\n",
            "('if', 'it'):1.0\n",
            "('is', 'designed'):0.018518518518518517\n",
            "('designed', 'to'):1.0\n",
            "('be', 'easily'):0.038461538461538464\n",
            "('easily', 'facts'):1.0\n",
            "('facts', 'forms'):1.0\n",
            "('forms', 'a'):0.3333333333333333\n",
            "('a', 'link'):0.00980392156862745\n",
            "('link', 'between'):1.0\n",
            "('between', 'IE'):0.125\n",
            "('IE', ','):1.0\n",
            "('a', 'recent'):0.00980392156862745\n",
            "('Processing', ','):0.1\n",
            "('and', 'logic'):0.00847457627118644\n",
            "('programming', 'with'):0.2\n",
            "('with', 'Prolog'):0.047619047619047616\n",
            "('Prolog', '.'):0.5\n",
            "('1', 'We'):0.1111111111111111\n",
            "('single', 'convolutional'):0.3333333333333333\n",
            "('convolutional', 'neural'):1.0\n",
            "('architecture', 'that'):0.25\n",
            "(',', 'given'):0.006578947368421052\n",
            "('given', 'a'):0.25\n",
            "('a', 'sentence'):0.00980392156862745\n",
            "('sentence', ','):0.5\n",
            "(',', 'outputs'):0.006578947368421052\n",
            "('outputs', 'a'):1.0\n",
            "('a', 'host'):0.00980392156862745\n",
            "('host', 'of'):1.0\n",
            "('processing', 'predictions'):0.015625\n",
            "('predictions', ':'):1.0\n",
            "(':', 'part-of-speech'):0.05263157894736842\n",
            "('part-of-speech', 'tags'):0.5\n",
            "('tags', ','):1.0\n",
            "(',', 'chunks'):0.006578947368421052\n",
            "('chunks', ','):0.5\n",
            "('entity', 'tags'):0.5\n",
            "('semantic', 'roles'):0.125\n",
            "('roles', ','):0.5\n",
            "(',', 'semantically'):0.006578947368421052\n",
            "('semantically', 'similar'):0.5\n",
            "('similar', 'words'):0.5\n",
            "('the', 'likelihood'):0.005434782608695652\n",
            "('likelihood', 'that'):1.0\n",
            "('that', 'the'):0.02631578947368421\n",
            "('the', 'sentence'):0.005434782608695652\n",
            "('sentence', 'makes'):0.5\n",
            "('makes', 'sense'):0.5\n",
            "('sense', '('):0.2\n",
            "('(', 'grammatically'):0.0196078431372549\n",
            "('grammatically', 'We'):1.0\n",
            "('We', 'developed'):0.041666666666666664\n",
            "('a', 'prototype'):0.00980392156862745\n",
            "('prototype', 'information'):1.0\n",
            "('system', 'which'):0.15384615384615385\n",
            "('which', 'uses'):0.1111111111111111\n",
            "('uses', 'advanced'):0.5\n",
            "('advanced', 'natural'):1.0\n",
            "('to', 'enhance'):0.013513513513513514\n",
            "('enhance', 'the'):1.0\n",
            "('the', 'effectiveness'):0.005434782608695652\n",
            "('effectiveness', 'of'):1.0\n",
            "('of', 'traditional'):0.005681818181818182\n",
            "('traditional', 'key-word'):0.5\n",
            "('key-word', 'based'):1.0\n",
            "('based', 'document'):0.125\n",
            "('document', 'retrieval'):0.2\n",
            "('retrieval', '.'):0.1111111111111111\n",
            "('The', 'backbone'):0.038461538461538464\n",
            "('backbone', 'of'):1.0\n",
            "('of', 'our'):0.011363636363636364\n",
            "('our', 'system'):0.25\n",
            "('system', 'is'):0.07692307692307693\n",
            "('statistical', 'retrieval'):0.14285714285714285\n",
            "('retrieval', 'engine'):0.1111111111111111\n",
            "('engine', 'which'):1.0\n",
            "('performs', 'automated'):0.5\n",
            "('automated', 'indexing'):0.2\n",
            "('indexing', 'Abstract'):1.0\n",
            "('will', 'discuss'):0.1111111111111111\n",
            "('several', 'issues'):0.25\n",
            "('issues', 'and'):0.5\n",
            "('and', 'requirements'):0.00847457627118644\n",
            "('requirements', 'for'):0.2\n",
            "('for', 'enabling'):0.017857142857142856\n",
            "('enabling', 'natural'):1.0\n",
            "('to', 'become'):0.013513513513513514\n",
            "('become', 'context-adaptive'):1.0\n",
            "('context-adaptive', '.'):1.0\n",
            "('.', 'Given'):0.00684931506849315\n",
            "('Given', 'the'):1.0\n",
            "('the', 'fact'):0.005434782608695652\n",
            "('fact', 'that'):1.0\n",
            "('that', 'emerging'):0.02631578947368421\n",
            "('emerging', 'systems'):1.0\n",
            "('systems', 'feature'):0.06666666666666667\n",
            "('feature', 'speaker'):1.0\n",
            "('speaker', 'independent'):1.0\n",
            "('independent', 'continuous'):0.5\n",
            "('continuous', 'speech'):1.0\n",
            "('recognition', 'restricted'):0.08333333333333333\n",
            "('restricted', 'to'):1.0\n",
            "('to', 'individual'):0.013513513513513514\n",
            "('individual', 'domains'):1.0\n",
            "('and', 'are'):0.01694915254237288\n",
            "('are', 'equipped'):0.038461538461538464\n",
            "('equipped', 'with'):1.0\n",
            "('with', 'syntactic'):0.047619047619047616\n",
            "('syntactic', 'In'):0.16666666666666666\n",
            "('In', 'Fall'):0.058823529411764705\n",
            "('Fall', '2004'):1.0\n",
            "('2004', 'I'):1.0\n",
            "('I', 'introduced'):1.0\n",
            "('introduced', 'a'):0.5\n",
            "('new', 'course'):0.16666666666666666\n",
            "('course', 'called'):1.0\n",
            "('called', 'Applied'):0.5\n",
            "('Applied', 'Natural'):1.0\n",
            "('in', 'which'):0.013333333333333334\n",
            "('which', 'students'):0.1111111111111111\n",
            "('students', 'acquire'):1.0\n",
            "('acquire', 'an'):0.5\n",
            "('an', 'understanding'):0.05\n",
            "('of', 'which'):0.005681818181818182\n",
            "('which', 'text'):0.1111111111111111\n",
            "('analysis', 'techniques'):0.09090909090909091\n",
            "('techniques', 'are'):0.07142857142857142\n",
            "('are', 'currently'):0.038461538461538464\n",
            "('currently', 'feasible'):1.0\n",
            "('feasible', 'for'):1.0\n",
            "('for', 'practical'):0.017857142857142856\n",
            "('practical', 'applications'):0.3333333333333333\n",
            "(':', 'Natural'):0.05263157894736842\n",
            "('the', 'study'):0.005434782608695652\n",
            "('of', 'mathematical'):0.005681818181818182\n",
            "('mathematical', 'and'):0.5\n",
            "('and', 'computational'):0.00847457627118644\n",
            "('computational', 'modelling'):0.2\n",
            "('modelling', 'of'):1.0\n",
            "('of', 'various'):0.005681818181818182\n",
            "('various', 'aspects'):0.125\n",
            "('language', 'and'):0.023529411764705882\n",
            "('a', 'wide'):0.029411764705882353\n",
            "('wide', 'range'):0.6666666666666666\n",
            "('of', 'systems'):0.005681818181818182\n",
            "('language', 'is'):0.011764705882352941\n",
            "('is', 'any'):0.018518518518518517\n",
            "('any', 'language'):1.0\n",
            "('language', 'that'):0.011764705882352941\n",
            "('that', 'arises'):0.02631578947368421\n",
            "('arises', 'as'):1.0\n",
            "('an', 'innate'):0.05\n",
            "('innate', 'facility'):1.0\n",
            "('facility', 'for'):1.0\n",
            "('for', 'language'):0.017857142857142856\n",
            "('language', 'possessed'):0.011764705882352941\n",
            "('possessed', 'by'):1.0\n",
            "('the', 'human'):0.005434782608695652\n",
            "('human', 'intellect'):1.0\n",
            "('intellect', ';'):1.0\n",
            "(';', 'it'):0.16666666666666666\n",
            "('it', 'may'):0.1\n",
            "('may', 'Natural'):0.3333333333333333\n",
            "(',', 'which'):0.006578947368421052\n",
            "('which', 'is'):0.1111111111111111\n",
            "('a', 'branch'):0.00980392156862745\n",
            "('branch', 'of'):1.0\n",
            "('intelligence', ','):0.5\n",
            "(',', 'includes'):0.006578947368421052\n",
            "('includes', 'speech'):0.3333333333333333\n",
            "('speech', 'synthesis'):0.125\n",
            "('synthesis', ','):1.0\n",
            "(',', 'Speech'):0.006578947368421052\n",
            "('Speech', 'recognition'):1.0\n",
            "('and', 'Machine'):0.00847457627118644\n",
            "('Machine', 'translation'):0.3333333333333333\n",
            "('translation', '.'):0.25\n",
            "('Processing', 'has'):0.05\n",
            "('has', 'a'):0.08333333333333333\n",
            "('of', 'applications'):0.011363636363636364\n",
            "('applications', 'in'):0.09090909090909091\n",
            "('the', 'Indian'):0.005434782608695652\n",
            "('Indian', 'context'):0.5\n",
            "('context', '.'):1.0\n",
            "('.', 'Most'):0.00684931506849315\n",
            "('Most', 'of'):1.0\n",
            "('the', 'rural'):0.005434782608695652\n",
            "('rural', 'Indian'):1.0\n",
            "('Indian', 'community'):0.5\n",
            "('community', 'is'):0.5\n",
            "('is', 'unable'):0.018518518518518517\n",
            "('unable', 'to'):1.0\n",
            "('to', 'make'):0.013513513513513514\n",
            "('use', 'An'):0.08333333333333333\n",
            "('An', 'Evaluation'):0.5\n",
            "('Evaluation', 'of'):1.0\n",
            "('of', 'LOLITA'):0.005681818181818182\n",
            "('LOLITA', 'and'):0.3333333333333333\n",
            "('and', 'related'):0.00847457627118644\n",
            "('related', 'Natural'):0.5\n",
            "('Processing', 'Systems'):0.05\n",
            "('Systems', 'Paul'):1.0\n",
            "('Paul', 'Callaghan'):1.0\n",
            "('Callaghan', 'Submitted'):1.0\n",
            "('Submitted', 'to'):1.0\n",
            "('the', 'University'):0.005434782608695652\n",
            "('University', 'of'):1.0\n",
            "('of', 'Durham'):0.005681818181818182\n",
            "('Durham', 'for'):1.0\n",
            "('the', 'degree'):0.005434782608695652\n",
            "('degree', 'of'):1.0\n",
            "('of', 'Ph.D.'):0.005681818181818182\n",
            "('Ph.D.', ','):1.0\n",
            "(',', 'August'):0.006578947368421052\n",
            "('August', '1997'):1.0\n",
            "('1997', '--'):1.0\n",
            "('--', '--'):0.6428571428571429\n",
            "('--', '-'):0.07142857142857142\n",
            "('-', 'This'):1.0\n",
            "('This', 'research'):0.034482758620689655\n",
            "('research', 'addresses'):0.08333333333333333\n",
            "('the', 'question'):0.005434782608695652\n",
            "('question', ','):1.0\n",
            "(',', '``'):0.006578947368421052\n",
            "('``', 'how'):0.2\n",
            "('how', 'do'):0.2\n",
            "('do', 'we'):0.3333333333333333\n",
            "('we', 'evaluate'):0.058823529411764705\n",
            "('evaluate', 'systems'):1.0\n",
            "('systems', 'like'):0.06666666666666667\n",
            "('like', 'LOLITA'):0.5\n",
            "('LOLITA', '?'):0.3333333333333333\n",
            "('?', \"''\"):0.2\n",
            "(\"''\", 'LOLITA'):0.2\n",
            "('LOLITA', 'is'):0.3333333333333333\n",
            "('the', 'Natural'):0.005434782608695652\n",
            "('Natural', 'Previous'):0.034482758620689655\n",
            "('Previous', 'work'):1.0\n",
            "('work', 'demonstrated'):0.14285714285714285\n",
            "('demonstrated', 'that'):1.0\n",
            "('that', 'Web'):0.02631578947368421\n",
            "('Web', 'counts'):1.0\n",
            "('counts', 'can'):0.5\n",
            "('to', 'approximate'):0.013513513513513514\n",
            "('approximate', 'bigram'):1.0\n",
            "('bigram', 'counts'):1.0\n",
            "('counts', ','):0.5\n",
            "(',', 'suggesting'):0.006578947368421052\n",
            "('suggesting', 'that'):1.0\n",
            "('that', 'Web-based'):0.02631578947368421\n",
            "('Web-based', 'frequencies'):0.5\n",
            "('frequencies', 'should'):1.0\n",
            "('should', 'be'):1.0\n",
            "('be', 'useful'):0.038461538461538464\n",
            "('useful', 'for'):1.0\n",
            "('wide', 'variety'):0.3333333333333333\n",
            "('variety', 'of'):1.0\n",
            "('.', 'However'):0.00684931506849315\n",
            "('However', ','):1.0\n",
            "(',', 'only'):0.006578947368421052\n",
            "('only', 'a'):0.5\n",
            "('a', 'limited'):0.00980392156862745\n",
            "('limited', 'number'):0.25\n",
            "('tasks', 'have'):0.0625\n",
            "('have', 'so'):0.08333333333333333\n",
            "('far', 'been'):0.5\n",
            "('been', 'tested'):0.07692307692307693\n",
            "('tested', 'using'):1.0\n",
            "('using', 'Web-scale'):0.09090909090909091\n",
            "('Web-scale', 'data'):1.0\n",
            "('data', 'sets'):0.16666666666666666\n",
            "('sets', 'This'):1.0\n",
            "('.', '16.1'):0.00684931506849315\n",
            "('16.1', 'Introduction'):1.0\n",
            "('Introduction', 'This'):0.2\n",
            "('chapter', 'focuses'):0.25\n",
            "('on', 'applications'):0.043478260869565216\n",
            "('applications', 'This'):0.09090909090909091\n",
            "('paper', 'describes'):0.047619047619047616\n",
            "('describes', 'a'):0.5\n",
            "('language', 'system'):0.011764705882352941\n",
            "('which', 'improves'):0.1111111111111111\n",
            "('improves', 'its'):1.0\n",
            "('its', 'own'):0.3333333333333333\n",
            "('own', 'performance'):1.0\n",
            "('performance', 'through'):0.25\n",
            "('through', 'learning'):0.5\n",
            "('The', 'system'):0.038461538461538464\n",
            "('system', 'processes'):0.07692307692307693\n",
            "('processes', 'short'):0.25\n",
            "('short', 'English'):0.5\n",
            "('English', 'narratives'):0.5\n",
            "('narratives', 'and'):1.0\n",
            "('and', 'is'):0.00847457627118644\n",
            "('is', 'able'):0.018518518518518517\n",
            "('to', 'acquire'):0.013513513513513514\n",
            "('acquire', ','):0.5\n",
            "(',', 'from'):0.006578947368421052\n",
            "('single', 'narrative'):0.3333333333333333\n",
            "('narrative', ','):1.0\n",
            "('new', 'schema'):0.16666666666666666\n",
            "('schema', 'for'):1.0\n",
            "('a', 'stereotypical'):0.00980392156862745\n",
            "('stereotypical', 'set'):1.0\n",
            "('set', 'of'):1.0\n",
            "('of', 'actions'):0.005681818181818182\n",
            "('actions', '.'):1.0\n",
            "('During', 'the'):0.5\n",
            "('the', 'understanding'):0.005434782608695652\n",
            "('understanding', 'process'):0.16666666666666666\n",
            "('process', ','):0.125\n",
            "('the', 'system'):0.005434782608695652\n",
            "('system', 'attempts'):0.07692307692307693\n",
            "('attempts', 'We'):1.0\n",
            "('We', 'classify'):0.041666666666666664\n",
            "('classify', 'and'):1.0\n",
            "('and', 'review'):0.00847457627118644\n",
            "('review', 'current'):0.5\n",
            "('current', 'approaches'):0.14285714285714285\n",
            "('to', 'software'):0.013513513513513514\n",
            "('software', 'infrastructure'):0.25\n",
            "('infrastructure', 'for'):1.0\n",
            "('for', 'research'):0.017857142857142856\n",
            "('research', ','):0.08333333333333333\n",
            "(',', 'development'):0.006578947368421052\n",
            "('development', 'and'):0.1111111111111111\n",
            "('and', 'delivery'):0.00847457627118644\n",
            "('delivery', 'of'):1.0\n",
            "('NLP', 'systems'):0.022727272727272728\n",
            "('The', 'task'):0.038461538461538464\n",
            "('task', 'Confidence'):0.25\n",
            "('Confidence', 'measures'):0.5\n",
            "('are', 'a'):0.07692307692307693\n",
            "('a', 'practical'):0.00980392156862745\n",
            "('practical', 'solution'):0.3333333333333333\n",
            "('solution', 'for'):0.5\n",
            "('for', 'improving'):0.017857142857142856\n",
            "('improving', 'the'):1.0\n",
            "('the', 'usefulness'):0.005434782608695652\n",
            "('usefulness', 'of'):1.0\n",
            "('Processing', 'applications'):0.05\n",
            "('.', 'Confidence'):0.00684931506849315\n",
            "('Confidence', 'estimation'):0.5\n",
            "('estimation', 'is'):0.5\n",
            "('a', 'generic'):0.00980392156862745\n",
            "('generic', 'machine'):0.3333333333333333\n",
            "('learning', 'approach'):0.05\n",
            "('for', 'deriving'):0.017857142857142856\n",
            "('deriving', 'confidence'):1.0\n",
            "('confidence', 'measures'):0.5\n",
            "('measures', '.'):0.3333333333333333\n",
            "('We', 'give'):0.041666666666666664\n",
            "('give', 'an'):1.0\n",
            "('overview', 'of'):0.5\n",
            "('of', 'confidence'):0.005681818181818182\n",
            "('confidence', 'estimation'):0.5\n",
            "('estimation', 'in'):0.5\n",
            "('various', 'fields'):0.125\n",
            "('fields', '!'):0.3333333333333333\n",
            "('!', 'lex-sign'):1.0\n",
            "('lex-sign', 'sense-id'):1.0\n",
            "('sense-id', ':'):0.5\n",
            "(':', 'sense-id'):0.15789473684210525\n",
            "('sense-id', 'dictionary'):0.16666666666666666\n",
            "('dictionary', '?'):0.5\n",
            "('?', '='):0.6\n",
            "('=', '``'):1.0\n",
            "('``', 'LDOCE'):0.2\n",
            "('LDOCE', \"''\"):0.5\n",
            "(\"''\", '!'):0.4\n",
            "('sense-id', 'ldb-entry-no'):0.16666666666666666\n",
            "('ldb-entry-no', '?'):1.0\n",
            "('``', '12364'):0.2\n",
            "('12364', \"''\"):1.0\n",
            "('sense-id', 'sense-no'):0.16666666666666666\n",
            "('sense-no', '?'):1.0\n",
            "('``', '0'):0.2\n",
            "('0', \"''\"):1.0\n",
            "(\"''\", '.'):0.2\n",
            "('.', 'When'):0.00684931506849315\n",
            "('When', 'loaded'):1.0\n",
            "('loaded', 'into'):1.0\n",
            "('into', 'the'):0.3333333333333333\n",
            "('the', 'LKB'):0.010869565217391304\n",
            "('LKB', ','):0.25\n",
            "(',', '('):0.006578947368421052\n",
            "('(', '9'):0.0392156862745098\n",
            "('9', ')'):1.0\n",
            "(')', 'will'):0.02127659574468085\n",
            "('be', 'expanded'):0.038461538461538464\n",
            "('expanded', 'into'):0.5\n",
            "('a', 'fully-fledged'):0.00980392156862745\n",
            "('fully-fledged', 'representation'):1.0\n",
            "('representation', 'for'):0.5\n",
            "('the', 'transitive'):0.005434782608695652\n",
            "('transitive', 'use'):1.0\n",
            "('of', 'experience'):0.005681818181818182\n",
            "('experience', ';'):0.5\n",
            "(';', 'by'):0.16666666666666666\n",
            "('by', 'integrating'):0.05555555555555555\n",
            "('integrating', 'word-specific'):0.5\n",
            "('word-specific', 'information'):1.0\n",
            "('information', 'provided'):0.05263157894736842\n",
            "('provided', 'by'):1.0\n",
            "('by', '('):0.05555555555555555\n",
            "(')', 'with'):0.02127659574468085\n",
            "('information', 'encoded'):0.05263157894736842\n",
            "('encoded', 'by'):1.0\n",
            "('LKB', 'type'):0.25\n",
            "('type', 'strict-trans-sign'):0.3333333333333333\n",
            "('strict-trans-sign', '.'):1.0\n",
            "('.', 'Thus'):0.00684931506849315\n",
            "('Thus', ','):1.0\n",
            "(',', 'although'):0.006578947368421052\n",
            "('although', 'neither'):1.0\n",
            "('neither', 'LDOCE'):1.0\n",
            "('LDOCE', ','):0.5\n",
            "(',', 'LLCE'):0.006578947368421052\n",
            "('LLCE', 'or'):1.0\n",
            "('or', 'the'):0.058823529411764705\n",
            "('the', 'earlier'):0.005434782608695652\n",
            "('earlier', 'subcategorised'):1.0\n",
            "('subcategorised', 'lexicon'):1.0\n",
            "('lexicon', 'contain'):1.0\n",
            "('contain', 'all'):1.0\n",
            "('about', 'psychological'):0.3333333333333333\n",
            "('psychological', 'verbs'):1.0\n",
            "('verbs', 'defined'):1.0\n",
            "('defined', 'in'):1.0\n",
            "('in', 'Sanfilippo'):0.013333333333333334\n",
            "('Sanfilippo', '&'):1.0\n",
            "('&', 'aposs'):0.3333333333333333\n",
            "('aposs', 'type'):1.0\n",
            "('type', 'system'):0.6666666666666666\n",
            "(',', 'by'):0.006578947368421052\n",
            "('by', 'using'):0.05555555555555555\n",
            "('using', 'the'):0.18181818181818182\n",
            "('the', 'conjunction'):0.005434782608695652\n",
            "('conjunction', 'of'):1.0\n",
            "('information', 'available'):0.05263157894736842\n",
            "('available', 'from'):1.0\n",
            "('from', 'all'):0.05555555555555555\n",
            "('all', 'three'):0.14285714285714285\n",
            "('three', ','):0.3333333333333333\n",
            "('it', 'proved'):0.1\n",
            "('proved', 'possible'):1.0\n",
            "('possible', 'to'):0.5\n",
            "('to', 'effectively'):0.013513513513513514\n",
            "('effectively', 'enrich'):0.3333333333333333\n",
            "('enrich', 'this'):1.0\n",
            "('this', 'information'):0.045454545454545456\n",
            "('information', 'at'):0.05263157894736842\n",
            "('same', 'time'):0.3333333333333333\n",
            "('time', 'as'):0.5\n",
            "('as', 'mapping'):0.06666666666666667\n",
            "('mapping', 'it'):1.0\n",
            "('it', 'into'):0.1\n",
            "('a', 'formal'):0.00980392156862745\n",
            "('formal', 'representation'):1.0\n",
            "('representation', '.'):0.5\n",
            "('.', '4.2.5'):0.00684931506849315\n",
            "('4.2.5', 'Towards'):1.0\n",
            "('Towards', 'a'):1.0\n",
            "('a', 'Multilingual'):0.00980392156862745\n",
            "('Multilingual', 'LKB'):1.0\n",
            "('LKB', 'A'):0.25\n",
            "('A', 'goal'):0.25\n",
            "('goal', 'of'):0.3333333333333333\n",
            "('of', 'ACQUILEX'):0.005681818181818182\n",
            "('ACQUILEX', 'is'):1.0\n",
            "('to', 'demonstrate'):0.013513513513513514\n",
            "('demonstrate', 'that'):1.0\n",
            "('that', 'an'):0.02631578947368421\n",
            "('an', 'LKB'):0.05\n",
            "('LKB', 'can'):0.25\n",
            "('be', 'produced'):0.038461538461538464\n",
            "('produced', 'that'):1.0\n",
            "('that', 'usefully'):0.02631578947368421\n",
            "('usefully', 'exploits'):1.0\n",
            "('exploits', 'various'):1.0\n",
            "('various', 'MRD'):0.125\n",
            "('MRD', 'sources'):1.0\n",
            "('sources', 'and'):1.0\n",
            "('and', 'integrates'):0.00847457627118644\n",
            "('integrates', 'multilingual'):1.0\n",
            "('multilingual', 'information'):1.0\n",
            "('The', 'use'):0.038461538461538464\n",
            "('a', 'common'):0.0196078431372549\n",
            "('common', 'LRL'):0.5\n",
            "('LRL', 'with'):1.0\n",
            "('common', 'type'):0.5\n",
            "(',', 'makes'):0.006578947368421052\n",
            "('makes', 'it'):0.5\n",
            "('it', 'possi'):0.1\n",
            "('possi', '...'):1.0\n",
            "('...', 'We'):1.0\n",
            "('the', 'Stanford'):0.005434782608695652\n",
            "('Stanford', 'CoreNLP'):1.0\n",
            "('CoreNLP', 'toolkit'):1.0\n",
            "('toolkit', ','):0.5\n",
            "(',', 'an'):0.006578947368421052\n",
            "('an', 'extensible'):0.05\n",
            "('extensible', 'pipeline'):1.0\n",
            "('pipeline', 'that'):1.0\n",
            "('that', 'provides'):0.02631578947368421\n",
            "('provides', 'core'):0.5\n",
            "('core', 'natural'):1.0\n",
            "('natural', 'lan-guage'):0.015625\n",
            "('lan-guage', 'analysis'):1.0\n",
            "('This', 'toolkit'):0.034482758620689655\n",
            "('toolkit', 'is'):0.5\n",
            "('is', 'quite'):0.018518518518518517\n",
            "('quite', 'widely'):1.0\n",
            "('widely', 'used'):1.0\n",
            "('used', ','):0.09090909090909091\n",
            "(',', 'both'):0.006578947368421052\n",
            "('both', 'in'):0.2\n",
            "('research', 'NLP'):0.08333333333333333\n",
            "('NLP', 'community'):0.022727272727272728\n",
            "('community', 'and'):0.5\n",
            "('and', 'also'):0.00847457627118644\n",
            "('also', 'among'):0.2\n",
            "('among', 'commercial'):0.3333333333333333\n",
            "('commercial', 'and'):1.0\n",
            "('and', 'govern-ment'):0.00847457627118644\n",
            "('govern-ment', 'users'):1.0\n",
            "('users', 'of'):1.0\n",
            "('of', 'open'):0.005681818181818182\n",
            "('open', 'source'):1.0\n",
            "('source', 'NLP'):1.0\n",
            "('NLP', 'technol-ogy'):0.022727272727272728\n",
            "('technol-ogy', '.'):1.0\n",
            "('We', 'suggest'):0.041666666666666664\n",
            "('suggest', 'Gaussian'):1.0\n",
            "('Gaussian', 'Processes'):1.0\n",
            "('Processes', '('):1.0\n",
            "('(', 'GPs'):0.0196078431372549\n",
            "('GPs', ')'):1.0\n",
            "('a', 'powerful'):0.00980392156862745\n",
            "('powerful', 'mod-elling'):0.5\n",
            "('mod-elling', 'framework'):1.0\n",
            "('framework', 'incorporating'):0.5\n",
            "('incorporating', 'kernels'):1.0\n",
            "('kernels', 'and'):1.0\n",
            "('and', 'Bayesian'):0.00847457627118644\n",
            "('Bayesian', 'inference'):1.0\n",
            "('inference', ','):1.0\n",
            "('are', 'recognised'):0.038461538461538464\n",
            "('recognised', 'as'):1.0\n",
            "('as', 'state-of-the-art'):0.06666666666666667\n",
            "('state-of-the-art', 'for'):1.0\n",
            "('for', 'many'):0.017857142857142856\n",
            "('many', 'machine'):0.5\n",
            "('learning', 'tasks'):0.05\n",
            "('.', ':'):0.00684931506849315\n",
            "(':', 'A'):0.05263157894736842\n",
            "('A', 'fundamental'):0.25\n",
            "('fundamental', 'issue'):0.5\n",
            "('issue', 'in'):0.3333333333333333\n",
            "('the', 'prerequisite'):0.005434782608695652\n",
            "('prerequisite', 'of'):1.0\n",
            "('an', 'enormous'):0.05\n",
            "('enormous', 'quantity'):1.0\n",
            "('quantity', 'of'):1.0\n",
            "('of', 'preprogrammed'):0.005681818181818182\n",
            "('preprogrammed', 'knowledge'):1.0\n",
            "('knowledge', 'concerning'):0.08333333333333333\n",
            "('concerning', 'both'):0.5\n",
            "('both', 'the'):0.2\n",
            "('the', 'language'):0.005434782608695652\n",
            "('the', 'domain'):0.005434782608695652\n",
            "('domain', 'under'):0.5\n",
            "('under', 'examination'):1.0\n",
            "('examination', '.'):1.0\n",
            "('.', 'Manual'):0.00684931506849315\n",
            "('Manual', 'acquisition'):1.0\n",
            "('acquisition', 'of'):0.3333333333333333\n",
            "('this', 'knowledge'):0.045454545454545456\n",
            "('knowledge', 'is'):0.08333333333333333\n",
            "('is', 'tedious'):0.018518518518518517\n",
            "('tedious', 'and'):1.0\n",
            "('and', 'error'):0.00847457627118644\n",
            "('error', 'prone'):1.0\n",
            "('prone', '.'):1.0\n",
            "('.', 'Development'):0.00684931506849315\n",
            "('Development', 'of'):1.0\n",
            "('an', 'automated'):0.05\n",
            "('automated', 'acquisition'):0.2\n",
            "('acquisition', '``'):0.3333333333333333\n",
            "('``', 'that'):0.2\n",
            "('that', 'supports'):0.02631578947368421\n",
            "('supports', 'sophisticated'):1.0\n",
            "('sophisticated', 'natural'):0.5\n",
            "('processing', 'while'):0.015625\n",
            "('while', 'significantly'):0.3333333333333333\n",
            "('significantly', 'simplifying'):1.0\n",
            "('simplifying', 'the'):1.0\n",
            "('the', 'interface'):0.005434782608695652\n",
            "('interface', 'between'):0.5\n",
            "('between', 'domain-specific'):0.125\n",
            "('domain-specific', 'knowledge'):1.0\n",
            "('knowledge', 'and'):0.08333333333333333\n",
            "('and', 'general'):0.00847457627118644\n",
            "('general', 'linguis-'):0.3333333333333333\n",
            "('linguis-', 'tic'):1.0\n",
            "('tic', 'resources'):1.0\n",
            "('paper', 'presents'):0.09523809523809523\n",
            "('presents', 'the'):0.3333333333333333\n",
            "('the', 'results'):0.005434782608695652\n",
            "('results', 'of'):0.14285714285714285\n",
            "('our', 'experiences'):0.25\n",
            "('experiences', 'in'):1.0\n",
            "('in', 'designing'):0.013333333333333334\n",
            "('designing', 'and'):1.0\n",
            "('and', 'using'):0.00847457627118644\n",
            "('the', 'upper'):0.005434782608695652\n",
            "('upper', 'model'):1.0\n",
            "('model', 'in'):0.14285714285714285\n",
            "('a', 'variety'):0.00980392156862745\n",
            "('applications', 'over'):0.09090909090909091\n",
            "('past', '5'):0.5\n",
            "('5', 'years'):1.0\n",
            "('years', 'into'):0.125\n",
            "('same', 'or'):0.3333333333333333\n",
            "('or', 'neighboring'):0.058823529411764705\n",
            "('neighboring', 'map'):1.0\n",
            "('map', 'nodes'):1.0\n",
            "('nodes', '.'):1.0\n",
            "('.', 'Nodes'):0.00684931506849315\n",
            "('Nodes', 'may'):1.0\n",
            "('may', 'thus'):0.3333333333333333\n",
            "('thus', 'be'):1.0\n",
            "('be', 'viewed'):0.038461538461538464\n",
            "('viewed', 'as'):1.0\n",
            "('as', 'word'):0.06666666666666667\n",
            "('word', 'categories'):0.14285714285714285\n",
            "('categories', '.'):1.0\n",
            "('.', 'Although'):0.00684931506849315\n",
            "('Although', 'no'):1.0\n",
            "('no', 'a'):1.0\n",
            "('a', 'priori'):0.00980392156862745\n",
            "('priori', 'information'):1.0\n",
            "('about', 'classes'):0.3333333333333333\n",
            "('classes', 'is'):0.3333333333333333\n",
            "('is', 'given'):0.018518518518518517\n",
            "('given', ','):0.25\n",
            "(',', 'during'):0.006578947368421052\n",
            "('the', 'self-organizing'):0.005434782608695652\n",
            "('self-organizing', 'process'):1.0\n",
            "('process', 'a'):0.125\n",
            "('a', 'model'):0.00980392156862745\n",
            "('word', 'classes'):0.14285714285714285\n",
            "('classes', 'emerges'):0.3333333333333333\n",
            "('emerges', '.'):1.0\n",
            "('The', 'central'):0.038461538461538464\n",
            "('central', 'topic'):1.0\n",
            "('topic', 'of'):1.0\n",
            "('the', 'thesis'):0.005434782608695652\n",
            "('thesis', 'is'):0.5\n",
            "('the', 'SOM'):0.005434782608695652\n",
            "('SOM', 'in'):1.0\n",
            "('The', 'approach'):0.038461538461538464\n",
            "('a', 'workbench'):0.00980392156862745\n",
            "('workbench', 'built'):0.5\n",
            "('built', 'by'):0.5\n",
            "('by', 'Priberam'):0.05555555555555555\n",
            "('Priberam', 'InformÃ¡tica'):1.0\n",
            "('InformÃ¡tica', 'for'):1.0\n",
            "('the', 'company'):0.005434782608695652\n",
            "('company', 'â€™'):1.0\n",
            "('â€™', 's'):1.0\n",
            "('s', 'natural'):1.0\n",
            "('processing', 'technology'):0.015625\n",
            "('technology', '.'):0.3333333333333333\n",
            "('This', 'workbench'):0.034482758620689655\n",
            "('workbench', 'includes'):0.5\n",
            "('a', 'set'):0.00980392156862745\n",
            "('linguistic', 'resources'):0.14285714285714285\n",
            "('resources', 'and'):0.2\n",
            "('software', 'tools'):0.25\n",
            "('tools', 'that'):0.3333333333333333\n",
            "('that', 'have'):0.02631578947368421\n",
            "('been', 'applied'):0.07692307692307693\n",
            "('applied', 'in'):0.25\n",
            "('a', 'considerable'):0.00980392156862745\n",
            "('considerable', 'number'):1.0\n",
            "('of', 'practical'):0.005681818181818182\n",
            "('practical', 'purposes'):0.3333333333333333\n",
            "('purposes', ','):0.5\n",
            "(',', 'covering'):0.006578947368421052\n",
            "('covering', 'Abstractâ€”Natural'):0.5\n",
            "('Abstractâ€”Natural', 'Language'):0.5\n",
            "('an', 'effective'):0.05\n",
            "('effective', 'approach'):0.25\n",
            "('for', 'bringing'):0.017857142857142856\n",
            "('bringing', 'improvement'):1.0\n",
            "('in', 'educational'):0.013333333333333334\n",
            "('educational', 'setting'):0.5\n",
            "('setting', '.'):1.0\n",
            "('.', 'Implementing'):0.00684931506849315\n",
            "('Implementing', 'NLP'):1.0\n",
            "('NLP', 'involves'):0.022727272727272728\n",
            "('involves', 'initiating'):0.5\n",
            "('initiating', 'the'):1.0\n",
            "('of', 'learning'):0.005681818181818182\n",
            "('learning', 'through'):0.05\n",
            "('through', 'the'):0.5\n",
            "('natural', 'acquisition'):0.015625\n",
            "('acquisition', 'in'):0.3333333333333333\n",
            "('the', 'educational'):0.005434782608695652\n",
            "('educational', 'systems'):0.5\n",
            "('It', 'is'):0.2\n",
            "('is', 'based'):0.018518518518518517\n",
            "('on', 'effective'):0.043478260869565216\n",
            "('effective', 'approaches'):0.25\n",
            "('approaches', 'for'):0.16666666666666666\n",
            "('for', 'providing'):0.017857142857142856\n",
            "('a', 'solution'):0.00980392156862745\n",
            "('solution', 'ABSTRACT'):0.5\n",
            "(':', 'After'):0.05263157894736842\n",
            "('After', 'twenty'):0.5\n",
            "('twenty', 'years'):1.0\n",
            "('years', 'of'):0.125\n",
            "('of', 'disfavor'):0.005681818181818182\n",
            "('disfavor', ','):1.0\n",
            "('a', 'technology'):0.00980392156862745\n",
            "('technology', 'has'):0.3333333333333333\n",
            "('has', 'returned'):0.08333333333333333\n",
            "('returned', 'which'):1.0\n",
            "('which', 'imitates'):0.1111111111111111\n",
            "('imitates', 'the'):1.0\n",
            "('processes', 'of'):0.25\n",
            "('the', 'brain'):0.005434782608695652\n",
            "('brain', '.'):1.0\n",
            "('language', 'experiments'):0.011764705882352941\n",
            "('experiments', '('):0.5\n",
            "('(', 'Sejnowski'):0.0196078431372549\n",
            "('Sejnowski', '&'):1.0\n",
            "('&', 'Rosenberg'):0.3333333333333333\n",
            "('Rosenberg', ':'):1.0\n",
            "(':', '1986'):0.05263157894736842\n",
            "('1986', ')'):1.0\n",
            "(')', 'demonstrate'):0.02127659574468085\n",
            "('that', 'neural'):0.02631578947368421\n",
            "('network', 'computing'):0.2\n",
            "('computing', 'architecture'):1.0\n",
            "('architecture', 'can'):0.25\n",
            "('can', 'learn'):0.0625\n",
            "('learn', 'from'):0.5\n",
            "('from', 'actual'):0.05555555555555555\n",
            "('actual', 'spoken'):1.0\n",
            "('spoken', 'language'):0.25\n",
            "('language', ','):0.011764705882352941\n",
            "(',', 'observe'):0.006578947368421052\n",
            "('observe', 'rules'):1.0\n",
            "('rules', 'of'):0.5\n",
            "('of', 'pronunciation'):0.005681818181818182\n",
            "('pronunciation', 'Text'):1.0\n",
            "('Text', 'statistics'):1.0\n",
            "('statistics', 'are'):0.5\n",
            "('are', 'frequently'):0.038461538461538464\n",
            "('frequently', 'used'):1.0\n",
            "('in', 'stylometry'):0.013333333333333334\n",
            "('stylometry', 'and'):1.0\n",
            "('and', 'cryptography'):0.00847457627118644\n",
            "('cryptography', 'studies'):1.0\n",
            "('studies', '.'):0.5\n",
            "('some', 'text'):0.2\n",
            "('text', 'statistics'):0.1\n",
            "('statistics', 'tools'):0.5\n",
            "('tools', 'are'):0.3333333333333333\n",
            "('are', 'developed'):0.038461538461538464\n",
            "('developed', 'in'):0.2\n",
            "('in', 'ISO'):0.013333333333333334\n",
            "('ISO', 'Prolog'):1.0\n",
            "('Prolog', 'for'):0.5\n",
            "('.', 'Details'):0.00684931506849315\n",
            "('Details', 'are'):1.0\n",
            "('are', 'given'):0.038461538461538464\n",
            "('given', 'on'):0.25\n",
            "('the', 'usage'):0.005434782608695652\n",
            "('usage', 'of'):1.0\n",
            "('of', '21'):0.005681818181818182\n",
            "('21', 'user-callable'):1.0\n",
            "('user-callable', 'predicates'):1.0\n",
            "('predicates', '.'):1.0\n",
            "('.', 'Logic'):0.00684931506849315\n",
            "('Logic', 'and'):1.0\n",
            "('and', 'limitations'):0.00847457627118644\n",
            "('limitations', 'of'):1.0\n",
            "('the', 'program'):0.005434782608695652\n",
            "('program', 'are'):0.3333333333333333\n",
            "('are', 'also'):0.038461538461538464\n",
            "('also', 'discussed'):0.2\n",
            "('discussed', 'We'):1.0\n",
            "('We', 'summarize'):0.041666666666666664\n",
            "('summarize', 'our'):1.0\n",
            "('our', 'experience'):0.25\n",
            "('experience', 'using'):0.5\n",
            "('using', 'FrameNet'):0.09090909090909091\n",
            "('FrameNet', 'in'):1.0\n",
            "('two', 'rather'):0.3333333333333333\n",
            "('rather', 'different'):0.3333333333333333\n",
            "('different', 'projects'):0.25\n",
            "('projects', 'in'):0.5\n",
            "('We', 'conclude'):0.041666666666666664\n",
            "('conclude', 'that'):1.0\n",
            "('that', 'NLP'):0.02631578947368421\n",
            "('NLP', 'can'):0.022727272727272728\n",
            "('can', 'benefit'):0.0625\n",
            "('benefit', 'from'):0.5\n",
            "('from', 'FrameNet'):0.05555555555555555\n",
            "('different', 'ways'):0.25\n",
            "('ways', ','):1.0\n",
            "('but', 'we'):0.16666666666666666\n",
            "('we', 'sketch'):0.058823529411764705\n",
            "('sketch', 'some'):1.0\n",
            "('some', 'problems'):0.2\n",
            "('problems', 'that'):0.3333333333333333\n",
            "('be', 'overcome'):0.038461538461538464\n",
            "('overcome', '.'):1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owQ9w5mqVUtd",
        "outputId": "4ae29c6e-a290-4e3c-d4ca-e1b1d91190a2"
      },
      "source": [
        "!pip install spacy\r\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "2Bc3tqzoXO8-",
        "outputId": "26282114-3b13-44c6-c90c-f35f3c6e20a0"
      },
      "source": [
        "import spacy\r\n",
        "nlp = spacy.load(\"en\")\r\n",
        "filename = open(\"Abstract.csv\",\"r\")\r\n",
        "d = nlp(filename.read())\r\n",
        "noun = []\r\n",
        "for p in d.noun_chunks:\r\n",
        "  noun.append(p.text)\r\n",
        "df = pd.DataFrame(noun, columns=['noun'])\r\n",
        "word_vectorizer = CountVectorizer(ngram_range=(3,3), analyzer='word')\r\n",
        "sparse_matrix = word_vectorizer.fit_transform(df['noun'].values.astype('U'))\r\n",
        "frequencies = sum(sparse_matrix).toarray()[0]\r\n",
        "df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(),columns=['Frequency'])\r\n",
        "df['NounProbabilities'] = df/df.max()\r\n",
        "print(noun)\r\n",
        "df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abstract\\n                     Abstract', 'a method', 'statistical modeling', 'maximum entropy', 'We', 'a maximum-likelihood approach', 'maximum entropy models', 'this approach', 'examples', 'several problems', 'natural language processing', 'conditional random fields', 'natural language processing Terms', 'Conditions', 'Terms', 'Conditions', 'Copyright', 'works', 'Minerva Access', 'The paper', 'the issue', 'cooperation', 'linguistics', 'natural language processing', 'NLP', 'linguistics', 'machine translation', '(MT', 'It', 'just one direction', 'such cooperation', 'namely applications', 'linguistics', 'NLP', 'most natural language processing applications', 'Description Logics', 'a knowledge base', 'some syntactic, semantic, and pragmatic elements', 'the semantic interpretation', 'the natural language generation', 'Description Logics', 'We', 'a unified neural network architecture', 'learning algorithm', 'various natural language processing tasks', 'speech', 'semantic role labeling', 'This versatility', 'task', 'The subject', 'Natural Language Processing', 'both broad and narrow senses', 'the broad sense', 'it', 'processing issues', 'all levels', 'natural language understanding', 'speech recognition', 'syntactic and semantic analysis', 'sentences                   \"\\n                     Robots', 'humans', 'face', 'natural language', 'the way', 'humans', 'language', 'those situations', 'We', 'a psychologicallyinspired natural language processing system', 'robots', 'incremental semantic interpretation', 'spoken utterances', 'Natural languages', 'languages', 'humans', 'we', 'the point', 'these languages', 'their unprocessed forms', 'computers', 'Natural language processing', 'the collection', 'techniques', 'that goal', 'The field', 'natural \\n\"                      ABSTRACT', 'Ambiguity', 'the ability', 'more than one meaning', 'more than one way', 'Natural languages', 'computers', 'language', 'people', 'Natural Language Processing', 'NLP', 'the development                   \"\\n                     Introduction  Statistical natural language processing', 'SNLP', 'a field', 'the intersection', 'natural language processing', 'machine learning', 'SNLP di#ers', 'traditional natural language processing', 'some model', '\"                      text', 'e.g. titles', 'abstracts', 'appropriate approaches', 'a focus', 'the role', 'natural language processing', 'The paper', 'possible connections', 'data and knowledge retrieval', 'the importance', '\"                     ABSTRACT', 'Language', 'way', 'your words', 'Language', 'the world', 'we', 'a better insight', 'the world', 'Language', 'speakers', 'they', 'NLP', 'natural language processing', 'Natural languages', 'those languages', 'We', 'experiments', 'the use', 'standard natural language processing (NLP) tools', 'the analysis', 'music lyrics', 'A significant amount', 'music audio', 'lyrics', 'Lyrics', 'an important part', 'the semantics', 'a song', 'their analysis', 'acoustic and cultural                   \"\\n\"                     this paper', 'we', 'a simple rule-based approach', 'automated learning', 'linguistic knowledge', 'This approach', 'a number', 'tasks', 'information', 'a clearer and more direct fashion', 'a compromise', 'performance', 'We', 'a detailed case study', 'this learning method', 'part', 'speech', 'This paper', 'connectionist models', 'natural language processing', 'We', 'several aspects', 'high level tasks', 'connectionism', 'localist or parallel distributed processing models', 'Several interesting architectures                   \"\\n process', 'language understanding', 'a new approach', 'natural language processing', 'the deterministic chaotic behavior', 'dynamical systems', 'a theoretical discussion', '[Kass', '[Leake', 'Owens', 'brief discussions', 'a program', 'the goal', 'our interest', 'natural language processing', 'us', '\"\\n                     Objectives', 'an overview', 'tutorial', 'natural language processing', 'NLP', 'modern NLP-system design', 'Target audience', 'This tutorial', 'the medical informatics generalist', 'who', 'acquaintance', 'the principles', 'NLP', 'the current state', 'This paper', 'the current implementation status', 'an intelligent information retrieval system', 'MARIE', 'natural language processing techniques', 'Descriptive captions', 'photographic images', 'various military projects', 'The captions', '\"\\n                      based and literature resources', 'We', 'a system', 'agent directed natural language processing', 'information', 'journal articles', 'An interface', 'curation', 'the NLP results', 'deposition', 'accepted results', 'a knowledge base', 'Motivation', 'The advent', 'speech processing', 'Part 2 surveys significant evaluation work', 'instance', 'machine translation', 'the particular problems', 'generic system evaluation', 'The conclusion', 'evaluation strategies', 'techniques', 'NLP', 'much more development', 'the way', 'humans', 'order', 'noisy content', 'this paper', 'we', 'a combination', 'HTML DOM analysis', 'Natural Language Processing (NLP) techniques', 'automated extractions', 'main article', 'associated images', 'web pages', 'Abstract-- Natural Language Processing', 'a theoretically motivated range', 'computational techniques', 'texts', 'one or more levels', 'linguistic analysis', 'the purpose', 'human-like language processing', 'a range', 'tasks', 'This paper', 'the processes', 'Natural Language Processing', 'NLP', 'It', 'the various kinds', 'choices', 'the execution', 'the word morphology', 'the syntactic text analysis', 'text generation components', 'It', 'the time', 'This article', 'the derivation', 'large lexicons', 'natural language processing', 'We', 'the  development', 'a dictionary support environment', 'a restructured version', 'the Longman  Dictionary', 'Contemporary English', 'natural language processing systems', 'The process', 'We', 'a method', 'the complexity', 'natural language processing tasks', 'the difficulty', 'new NLP tasks', 'Our complexity measures', 'the Kolmogorov complexity', 'a class', 'automata', 'automata', 'whose purpose', 'relevant pieces', 'text', 'motion', 'The techniques', 'deep learning research', 'the research', 'natural language process', 'This paper', 'the recent research', 'deep learning', 'its applications', 'recent development', 'natural language processing', 'an author-produced version', 'a paper', 'Abstract', 'Natural language processing', 'NLP', 'the application', 'automated parsing and machine learning techniques', 'standard text', 'Applications', 'NLP', 'extraction', 'ontologies', 'a requirements specification', 'use', 'NLP', 'the consistency', 'statistical  baseline', 'the forgiving nature', 'broad coverage', 'the  typical retrieval task', 'the lack', 'good weighting schemes', 'compound  index terms', 'the statistical  methods', 'Natural language processing techniques', 'Work', 'computational linguistics', 'the development', 'the first computers', 'Booth', 'Brandwood', 'Cleave', 'the intervening four decades', 'a pervasive feeling', 'progress', 'computer understanding', 'natural language', 'the voice recognition', 'a natural language', 'Tamil', 'the digital and mathematical knowledge', 'MFCC', 'DTW', 'the features', 'the accuracy', 'better performance', 'Abstract', 'natural language requirements', 'the standard approach', 'system', 'acceptance testing', 'This test', 'an independent test organization', 'the application area', 'The only things', 'the testers', 'the written requirements', 'Abstract', 'conversational partners', 'it', 'us', 'information', 'associations', 'storytelling', 'language use', 'Many more subtleties', 'face', 'humor', 'a face threatening act', 'Abstract', 'recent years', 'machine learning', 'ML', 'complex tasks', 'different disciplines', 'Data Mining', 'Information', 'We', 'manual and automatic thesauruses', 'alternative resources', 'the same NLP tasks', 'the radical step', 'manual thesauruses', 'classifications', 'words', 'word senses', 'the case', 'The range', 'roles', 'thesauruses', 'NLP', 'the WASPS thesaurus', 'Thesaurus evaluation', 'A range', 'evaluation strategies', 'NLP tasks', 'Introduction  Patterns', 'music', 'the object', 'intensive studies', 'the past years', 'the purposes', 'musical structure', 'form', 'the patterns', 'musical works', '\" Simon', 'Patterns', 'periodicity', 'use', 'alphabets', 'can be compound', 'subpatterns', 'phrase structure', 'various forms', 'punctuation', 'composers', 'pattern propagation', 'algorithmic composition techniques', 'the pattern propagation', 'a high level', 'composition', 'all the musical patterns', 'the rules', 'constraints', 'the design stage', 'jazz improvisation', 'the musician', 'a solo', 'a progression', 'chords', 'the changes', 'One approach', 'to memorize patterns', 'short chunks', 'music', 't sub-progressions', 'them', 'a whole solo', 'a whole progression', '\"                     Abstract Many information retrieval(IR) systems', 'relevant documents', 'exact matching', 'keywords', 'a query', 'documents', 'This method', 'precision rate', 'order', 'the problem', 'we', 'semantically related words', 'assigned semantic relationships', 'general thesaurus', 'a special relationship', 'addition', 'the semantic knowledge', 'we', 'statistic knowledge', 'the concept', 'mutual information', 'Keyfact', 'an extended concept', 'keyword', 'compound noun', 'Keyfact', 'an adjective', 'subject or object term', 'We', 'relevant documents', 'original query', 'tf * idf weighting formula', 'an expanded query', 'keyfacts', 'both second document ranking', 'word sense disambiguating', 'we', 'an improvement', 'precision rate', 'keyfact network', 'we', 'technical domains', 'TREC-based  QA', 'Web-based QA', 'it', 'lom data-intensive approaches', 'des Saarlandes', 'Proceedings', 'the Workshop', 'Abstract', 'Abstract', 'SRI', 'a new architecture', 'speech', 'natural-language processing', 'linguistic constraints', 'recognition', 'the state-transition network', 'a unification grammar', 'We', '(DGN', 'This chapter', 'the revolution', 'place', 'natural language processing research', 'the last five years', 'It', 'a brief guide', 'the structure', 'the field', 'a caricature', 'two competing paradigms', '1980s NLP research', 'the reasons', 'visual development environment', 'the visual assembly', 'execution', 'analysis', 'modular natural language processing systems', 'The visual model', 'an executable data flow program graph', 'data dependency declarations', 'language processing modules', 'The graph', 'this Chapter', 'Description Logics', 'Natural Language Processing', 'a little bit', 'history', 'the role', 'Description Logics', 'the current state', 'the art', 'computational linguistics', '18.1 Introduction', 'the early days', 'We', 'a structure learning model', 'Max-Margin Structure', 'MMS', 'natural language processing (NLP) tasks', 'the aim', 'the latent relationships', 'the output language domain', 'We', 'this model', 'an extension', 'class Support Vector Machine', '(SVM', 'a                   \"\\n\"                     -mation Infrastructure', 'digital libraries', 'networked services', 'digital convergence', 'intelligent agents', 'This attention', 'natural language processing', 'the critical path', 'all kinds', 'novel applications', 'This article', 'a number', 'successful applications', 'natural language processing', 'NLP', 'the last few years', 'a number', 'areas', 'natural language processing', 'graph-based techniques', 'others', 'Natural Language Processing', 'research results', 'software engineering and software technology', 'its robustness', 'performance', 'several Natural Language Processing (NLP) tasks', 'document', 'comparable corpora', 'machine transliteration', 'even image processing', 'we', 'these tasks', 'a semi-supervised variant', 'the words', 'statistical natural language processing', 'we', 'a sophisticated statistical model', 'the basic elements', 'words', 'phrases', 'the structural modeling', 'syntactic parsing', 'dependency analysis', 'the basic property', 'these elements', 'this paper', 'we', 'a framework', 'probabilistic classifiers', 'natural language processing', 'Our focus', 'models', 'the most important interdependencies', 'features', 'the data', 'the data', 'The class', '\"                     Many Natural Language Processing (NLP) techniques', 'Information Retrieval', 'The results', 'Simple methods', 'significant improvements', 'higher-level processing', 'chunking', 'parsing', 'word sense disambiguation', 'Abstract-', 'This paper', 'the information retrieval', 'natural language processing', 'Malayalam language', 'the state', 'the art plan recognition systems', 'This paper', 'the relations', 'natural language processing(NLP', 'them', 'key recent research results', 'NLP', 'their applicability', 'the state', 'the art plan recognition systems', 'This paper', 'the relations', 'natural language processing(NLP', 'them', 'key recent research results', 'NLP', 'their applicability', 'PR.', '\"                     Information retrieval', 'the process', 'the documents', 'a document collection', 'the information', 'the user', 'The documents', 'natural language constructs', 'the motivation', 'this work', 'natural language processing', 'logic programming', 'both natural language research and machine learning', 'we', 'opportunities', 'induction', 'linguistic knowledge', 'logic', 'programming', 'Keywords', 'inductive logic programming', 'natural language processing', 'logic programming', 'machine learning', '1 Introduction', 'What', 'a statistical method', 'it', 'natural language processing', 'NLP', 'this paper', 'we', 'a definition', 'NLP', 'the design', 'implementation', 'effective natural language input and output components', 'computational systems', 'We', 'this report', 'some collaborative work', 'the fields', 'Machine Learning', 'ML', 'Natural Language Processing', 'NLP', 'The document', 'two parts', 'The first part', 'a superficial but comprehensive survey', 'the state', 'the--art', 'Abstract', 'This thesis', 'the use', 'techniques', 'various tasks', 'natural language processing', 'the task', 'information extraction', 'texts', 'The objectives', 'the improvement', 'adaptability', 'information extraction systems', 'new thematic do-mains', 'This chapter', 'the application', 'natural language processing', 'language learning', 'the history', 'work', 'this field', 'the last thirtyfive years', 'a focus', 'current developments', 'opportunities', '36.1                    \\n\"                     Traditional approaches tointerpretation', 'natural language processing', 'three classes', 'Syntax-driven approaches', 'a domain-independent grammar', 'the interpretation process', 'a global parse', '\" Natural Language Processing (NLP', 'a very large and diverse subtopic', 'artificial intelligence', 'a result', 'NLP', 'itself', 'many subtopics', 'optical character recognition', 'text', 'translators', 'foreign language reading and writing aids', 'machine translation', 'speech recognition', '\"\\n\"                       Probabilistic finite-state string transducers', 'FSTs', 'natural language processing', 'powerful generic methods', 'composing', 'them', 'FSTs', 'a good fit', 'the current work', 'probabilistic modeling', 'machine', '\"\\n\"                     ABSTRACT', 'this special issue', 'TAL', 'we', 'the fundamental principles', 'underlying evaluation', 'natural language processing', 'We', 'a global point', 'view', 'the horizon', 'a single evaluation campaign', 'a particular protocol', 'a brief review', 'history', 'Abstract', '(NLP', 'clinical information', 'textual reports', 'limited domains', 'particular applications', 'an NLP system', 'substantial resources', 'it', 'it', 'a link', 'IE', 'a recent development', 'Natural Language Processing', 'logic programming', 'We', 'a single convolutional neural network architecture', 'a sentence', 'a host', 'language processing predictions', 'speech', 'chunks', 'the sentence', 'sense', 'We', 'a prototype information retrieval system', 'advanced natural language', 'techniques', 'the effectiveness', 'traditional  key-word based document retrieval', 'The backbone', 'our system', 'a statistical retrieval engine', 'automated indexing', 'Abstract', 'this paper', 'we', 'several issues', 'requirements', 'natural language processing systems', 'the fact', 'emerging systems', 'speaker independent continuous speech recognition', 'individual domains', 'Fall', 'I', 'a new course', 'students', 'an understanding', 'analysis techniques', 'practical applications', 'Abstract', 'Abstract: Natural language processing', 'the study', 'mathematical and computational modelling', 'various aspects', 'language', 'the improvement', 'a wide range', 'systems', 'Natural language', 'any language', 'an innate facility', 'language', 'the human intellect', 'it', 'Natural Language Processing', '(NLP', 'a branch', 'artificial intelligence', 'speech synthesis', 'Speech recognition', 'Machine translation', 'Natural Language Processing', 'a wide range', 'applications', 'the Indian context', 'the rural Indian community', 'use', '\"                     An Evaluation', 'LOLITA', 'Natural Language Processing Systems', 'Paul Callaghan', 'the University', 'Durham', 'the degree', 'Ph.D.', 'August', 'This research', 'the question', 'we', 'systems', 'LOLITA', 'LOLITA', 'the Natural', 'Previous work', 'Web counts', 'bigram counts', 'Web-based frequencies', 'a wide variety', 'Natural Language Processing (NLP) tasks', 'only a limited number', 'tasks', 'Web-scale data sets', 'This chapter', 'the application', 'natural language processing', 'language learning', 'the history', 'work', 'this field', 'the last thirtyfive years', 'a focus', 'current developments', 'opportunities', '16.1 Introduction', 'This chapter', 'applications', 'This paper', 'a natural language system', 'its own performance', 'learning', 'The system', 'short English narratives', 'a single narrative', 'a new schema', 'a stereotypical set', 'actions', 'the understanding process', 'the system', 'We', 'current approaches', 'infrastructure', 'research', 'development', 'delivery', 'NLP systems', 'The task                   \"\\n                     Confidence measures', 'a practical solution', 'the usefulness', 'Natural Language Processing applications', 'Confidence estimation', 'a generic machine learning approach', 'deriving confidence measures', 'We', 'an overview', 'the application', 'confidence estimation', 'various fields', 'lex-sign sense', '-id', 'sense-id', '\"\"LDOCE', 'lex-sign sense-id', 'sense-id ldb-entry', '-no', 'lex-sign sense-id', 'sense-id sense', 'the LKB', 'a fully-fledged representation', 'the transitive use', 'experience', 'word-specific information', 'the information', 'the LKB type', 'strict-trans-sign', 'neither LDOCE', 'LLCE', 'the earlier subcategorised lexicon', 'all the information', 'psychological verbs', 'Sanfilippo&aposs type system', 'the conjunction', 'information', 'it', 'this information', 'the same time', 'it', 'a formal representation', 'a Multilingual LKB', 'A goal', 'ACQUILEX', 'an LKB', 'various MRD sources', 'multilingual information', 'The use', 'a common LRL', 'a common type system', 'it', 'We', 'the design', 'use', 'the Stanford CoreNLP toolkit', 'an extensible pipeline', 'core natural lan-guage analysis', 'This toolkit', 'the research NLP community', 'commercial and govern-ment users', 'open source NLP technol-ogy', 'We', 'Gaussian Processes', 'GPs', 'a powerful mod-elling framework', 'kernels', 'Bayesian inference', 'state', 'the-art', 'many machine learning tasks', 'A fundamental issue', 'natural language processing', 'the prerequisite', 'an enormous quantity', 'preprogrammed knowledge', 'both the language', 'the domain', 'examination', 'Manual acquisition', 'this knowledge', 'Development', 'an automated acquisition', 'sophisticated natural language processing', 'the interface', 'domain-specific knowledge', 'general linguis- tic resources', 'This paper', 'the results', 'our experiences', 'the upper model', 'a variety', 'applications', 'the past 5 years', 'the same or neighboring map nodes', 'Nodes', 'word categories', 'no a priori information', 'classes', 'the self-organizing process', 'a model', 'the word classes', 'The central topic', 'the thesis', 'the use', 'the SOM', 'natural language processing', 'The approach', 'This paper', 'a workbench', 'Priberam InformÃ¡tica', 'the development', 'the companyâ€™s natural language processing technology', 'This workbench', 'a set', 'linguistic resources', 'software tools', 'a considerable number', 'practical purposes', 'Abstract', 'Natural Language Processing', 'NLP', 'an effective approach', 'improvement', 'educational setting', 'Implementing NLP', 'the process', 'the natural acquisition', 'the educational systems', 'It', 'effective approaches', 'a solution', 'ABSTRACT', 'twenty years', 'disfavor', 'a technology', 'the processes', 'the brain', 'Natural language experiments', 'Sejnowski', 'Rosenberg', 'neural network computing architecture', 'actual spoken language', 'rules', 'pronunciation', 'Text statistics', 'stylometry', 'cryptography studies', 'this paper', 'some text statistics tools', 'ISO Prolog', 'natural language processing', 'Details', 'the usage', '21 user-callable predicates', 'Logic', 'limitations', 'the program', 'We', 'our experience', 'FrameNet', 'two rather different projects', 'natural language processing', '(NLP', 'We', 'NLP', 'FrameNet', 'different ways', 'we', 'some problems']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frequency</th>\n",
              "      <th>NounProbabilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1980s nlp research</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21 user callable</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36 traditional approaches</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abstract many information</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abstract natural language</th>\n",
              "      <td>2</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>web scale data</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word based document</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word sense disambiguating</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word sense disambiguation</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word specific information</th>\n",
              "      <td>1</td>\n",
              "      <td>0.013889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>367 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Frequency  NounProbabilities\n",
              "1980s nlp research                 1           0.013889\n",
              "21 user callable                   1           0.013889\n",
              "36 traditional approaches          1           0.013889\n",
              "abstract many information          1           0.013889\n",
              "abstract natural language          2           0.027778\n",
              "...                              ...                ...\n",
              "web scale data                     1           0.013889\n",
              "word based document                1           0.013889\n",
              "word sense disambiguating          1           0.013889\n",
              "word sense disambiguation          1           0.013889\n",
              "word specific information          1           0.013889\n",
              "\n",
              "[367 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "e62cbdc5-db8f-40a7-8398-d50891d4c349"
      },
      "source": [
        "import math\r\n",
        "def value(s,w):\r\n",
        "  l=len(s.split(' '))\r\n",
        "  tf_value=s.count(w)/l\r\n",
        "  idf_value=0\r\n",
        "  if(tf_value!=0):\r\n",
        "    idf_value=math.log(l)/s.count(w)\r\n",
        "  else:\r\n",
        "    return 0;\r\n",
        "  return tf_value*idf_value\r\n",
        "s1=f['Abstract'].values.tolist()\r\n",
        "l1=set([i for j in s1 for i in j.split(' ')])\r\n",
        "tf_idf=pd.DataFrame(l1,columns=['token'])\r\n",
        "c=0\r\n",
        "for i in s1:\r\n",
        "  tf_idf[str(c)]=tf_idf['token'].apply(lambda x: value(i,x))\r\n",
        "  c+=1\r\n",
        "tf_idf\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.054252</td>\n",
              "      <td>0.064221</td>\n",
              "      <td>0.054252</td>\n",
              "      <td>0.054252</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.066567</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.07824</td>\n",
              "      <td>0.050879</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.050879</td>\n",
              "      <td>0.051332</td>\n",
              "      <td>0.047545</td>\n",
              "      <td>0.055309</td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.049998</td>\n",
              "      <td>0.054252</td>\n",
              "      <td>0.055855</td>\n",
              "      <td>0.051332</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.064983</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.054252</td>\n",
              "      <td>0.077095</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.050879</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.058773</td>\n",
              "      <td>0.052748</td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.064221</td>\n",
              "      <td>0.041835</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04957</td>\n",
              "      <td>0.04957</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.05374</td>\n",
              "      <td>0.050434</td>\n",
              "      <td>0.05374</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.055855</td>\n",
              "      <td>0.057567</td>\n",
              "      <td>0.067391</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.050879</td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.064983</td>\n",
              "      <td>0.068239</td>\n",
              "      <td>0.055309</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.058163</td>\n",
              "      <td>0.08747</td>\n",
              "      <td>0.051332</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.062052</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.052748</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.067391</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.026708</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.048333</td>\n",
              "      <td>0.05374</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.055855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cannot</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Speech</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>convergence</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>includes</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1429</th>\n",
              "      <td>(made</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>computational</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054775</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.050434</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.051332</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431</th>\n",
              "      <td>report</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051332</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.064983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1432</th>\n",
              "      <td>prerequisite</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1433</th>\n",
              "      <td>solve</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.064221</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1434 rows Ã— 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              token        0         1  ...        97        98        99\n",
              "0                    0.08747  0.054252  ...  0.054775  0.052266  0.055855\n",
              "1            cannot  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2            Speech  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "3       convergence  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4          includes  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "...             ...      ...       ...  ...       ...       ...       ...\n",
              "1429          (made  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1430  computational  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1431         report  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1432   prerequisite  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1433          solve  0.00000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "\n",
              "[1434 rows x 101 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "A-wmU1WrgFCs",
        "outputId": "bcea9e10-6261-48c3-91a3-d4a48ecb6a9e"
      },
      "source": [
        "import numpy.linalg as alg\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "x = f['Abstract'].values.tolist()\r\n",
        "test = [\"Natural language\"]\r\n",
        "stop = stopwords.words('english')\r\n",
        "vectorizer = CountVectorizer(stop_words = stop)\r\n",
        "transformer = TfidfTransformer()\r\n",
        "array = vectorizer.fit_transform(x).toarray()\r\n",
        "tarray = vectorizer.transform(test).toarray()\r\n",
        "cx = lambda a,b : np.inner(a,b)/(alg.norm(a)*alg.norm(b))\r\n",
        "result = []\r\n",
        "for v in array:\r\n",
        "  for t in tarray:\r\n",
        "    cosine = cx(v, t)\r\n",
        "    result.append(cosine)\r\n",
        "p = f.filter(['No','Cleaned_title'], axis=1)\r\n",
        "s = pd.Series(result)\r\n",
        "p['Cosine_similarity'] = s.values\r\n",
        "p.drop(p.loc[p['Cosine_similarity']==0].index, inplace=True)\r\n",
        "p[\"Rank\"] = p[\"Cosine_similarity\"].rank().astype(int)\r\n",
        "p.sort_values(\"Cosine_similarity\", inplace=True)\r\n",
        "p"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cosine_similarity</th>\n",
              "      <th>Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0.116248</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.121268</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.121268</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0.218218</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.218218</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.566947</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.612372</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.612372</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.618853</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0.714435</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>78 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Cosine_similarity  Rank\n",
              "90           0.116248     1\n",
              "35           0.121268     2\n",
              "75           0.121268     2\n",
              "88           0.218218     4\n",
              "84           0.218218     4\n",
              "..                ...   ...\n",
              "59           0.566947    74\n",
              "12           0.612372    75\n",
              "10           0.612372    75\n",
              "6            0.618853    77\n",
              "81           0.714435    78\n",
              "\n",
              "[78 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "# The GitHub link of your final csv file\n",
        "\n",
        "# Link: https://github.com/hariprasad7/info5731_spring2021/blob/main/SENTIMENT%20(2).csv"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}